{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e4af0c-18f3-43f4-b418-17b48f156ef8",
   "metadata": {},
   "source": [
    "# Trendspotting POC\n",
    "\n",
    "Goal of this notebook is to\n",
    "* Load signals data into a managed vertex dataset for time series forecasting\n",
    "* Create a forecast prediction model for each term, geo and category combination\n",
    "* Project the forecasts on a holdout set of data to assess performance and trends\n",
    "* Clean up results of test predictions\n",
    "* Cluster test predictions\n",
    "* Create dashboard for backtesting\n",
    "\n",
    "End users would take this parameterized pipeline to produce futurama backtests using clustering and forecasting\n",
    "\n",
    "[Source Control Link](https://source.cloud.google.com/cpg-cdp/trendspotting/+/master:pipeline_train.ipynb)\n",
    "\n",
    "When run - the piepline will look something like this:\n",
    "\n",
    "![pipeline example](img/pipeline_example.png)\n",
    "\n",
    "[Link to pipeline](https://pantheon.corp.google.com/vertex-ai/locations/us-central1/pipelines/runs/report-pipe-trendspotting-pipeline-20220309212043?authuser=0&project=cpg-cdp)\n",
    "## Install packages, create bucket (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d303d30-5821-4179-a13d-3c49455e72ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.7/site-packages (1.44.0)\n",
      "Collecting google-cloud-storage\n",
      "  Using cached google_cloud_storage-2.3.0-py2.py3-none-any.whl (107 kB)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (1.35.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.26.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-storage) (2.3.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-storage) (2.3.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (1.31.5)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (3.19.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (21.3)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (2021.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (59.6.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.53.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.16.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.8)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media>=2.3.2->google-cloud-storage) (1.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.0.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media>=2.3.2->google-cloud-storage) (2.21)\n",
      "Installing collected packages: google-cloud-storage\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 1.44.0\n",
      "    Uninstalling google-cloud-storage-1.44.0:\n",
      "      Successfully uninstalled google-cloud-storage-1.44.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-mlflow 0.0.5 requires google-cloud-storage==1.*, but you have google-cloud-storage 2.3.0 which is incompatible.\n",
      "kfp 1.8.12 requires google-cloud-storage<2,>=1.20.0, but you have google-cloud-storage 2.3.0 which is incompatible.\n",
      "google-cloud-pipeline-components 1.0.5 requires google-cloud-storage<2,>=1.20.0, but you have google-cloud-storage 2.3.0 which is incompatible.\u001b[0m\n",
      "Successfully installed google-cloud-storage-2.3.0\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: kfp in /opt/conda/lib/python3.7/site-packages (1.8.12)\n",
      "Requirement already satisfied: google-cloud-pipeline-components==1.0.5 in /opt/conda/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2,>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pipeline-components==1.0.5) (1.11.0)\n",
      "Collecting google-cloud-storage<2,>=1.20.0\n",
      "  Using cached google_cloud_storage-1.44.0-py2.py3-none-any.whl (106 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pipeline-components==1.0.5) (1.31.5)\n",
      "Requirement already satisfied: google-cloud-notebooks>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pipeline-components==1.0.5) (1.1.1)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.7/site-packages (from jupyter) (6.6.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from jupyter) (6.3.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.7/site-packages (from jupyter) (7.6.5)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.7/site-packages (from jupyter) (5.2.2)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.7/site-packages (from jupyter) (6.4.0)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.7/site-packages (from jupyter) (6.4.6)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (18.20.0)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.14 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.1.14)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.19.1)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.2.13)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.10.0.2)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (8.0.3)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.7.1)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.12.10)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.0.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (2.0.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.13)\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.0.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.8.9)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.35.0)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.1.10)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.8.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<2,>=0.9->kfp) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9,>=7.1.2->kfp) (4.9.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.13.3)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.5) (1.53.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.5) (59.6.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.5) (2.26.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.5) (21.3)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.5) (2021.3)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.20.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.7)\n",
      "Requirement already satisfied: proto-plus>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components==1.0.5) (1.19.8)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components==1.0.5) (2.31.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->google-cloud-pipeline-components==1.0.5) (2.3.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->google-cloud-pipeline-components==1.0.5) (2.3.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.7)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.2.3)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (7.1.0)\n",
      "Requirement already satisfied: traitlets<6.0,>=5.1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (1.5.1)\n",
      "Requirement already satisfied: argcomplete>=1.12.3 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (1.12.3)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (7.30.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->jupyter) (1.0.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->jupyter) (5.1.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->jupyter) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->jupyter) (3.5.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-console->jupyter) (3.0.24)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from jupyter-console->jupyter) (2.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: jinja2>=2.4 in /home/jupyter/.local/lib/python3.7/site-packages (from nbconvert->jupyter) (3.1.1)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (4.9.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (0.5.9)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (0.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter) (0.12.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter) (21.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter) (22.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter) (0.12.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter) (1.5.4)\n",
      "Requirement already satisfied: qtpy in /opt/conda/lib/python3.7/site-packages (from qtconsole->jupyter) (1.11.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.5) (1.43.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->google-cloud-pipeline-components==1.0.5) (1.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<9,>=7.1.2->kfp) (3.6.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.18.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jupyter/.local/lib/python3.7/site-packages (from jinja2>=2.4->nbconvert->jupyter) (2.1.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter) (0.2.5)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.5) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.5) (3.1)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.7/site-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.1.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
      "Installing collected packages: google-cloud-storage\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.3.0\n",
      "    Uninstalling google-cloud-storage-2.3.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.3.0\n",
      "Successfully installed google-cloud-storage-1.44.0\n",
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.7/site-packages (1.11.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.44.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (21.3)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.31.5)\n",
      "Requirement already satisfied: proto-plus>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.19.8)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2.26.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.53.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (3.19.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2021.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (59.6.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.35.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.43.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-aiplatform) (3.0.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (4.8)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2021.10.8)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (0.4.8)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.21)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -U google-cloud-storage $USER_FLAG\n",
    "! pip3 install $USER kfp google-cloud-pipeline-components==1.0.5\n",
    "# !git clone https://github.com/kubeflow/pipelines.git\n",
    "# !pip install pipelines/components/google-cloud/.\n",
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15945c-b978-45c4-9ecc-87e17c4097b6",
   "metadata": {},
   "source": [
    "### Import libs and types for KFP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b2a410-def8-43de-aa41-2ed9efe75d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from google import auth\n",
    "from google.api_core import exceptions as google_exceptions\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.experimental import forecasting as gcc_aip_forecasting\n",
    "from google_cloud_pipeline_components.experimental import bigquery as gcp_aip_bq\n",
    "\n",
    "import google.cloud.aiplatform\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "from typing import Dict, List, Optional, Sequence, Tuple, Union\n",
    "from kfp.v2.dsl import Artifact\n",
    "from kfp.v2.dsl import Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95fbc67-a62b-42f2-a756-a6e304bf582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'cpg-cdp'\n",
    "LOCATION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b675de8f-00f9-4d2f-9d5c-73e3d9e78683",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINES = {}\n",
    "\n",
    "PIPELINES_FILEPATH = 'gs://trendspotting-pipeline' # <--- TODO: CHANGE THIS; can be blank json file\n",
    "\n",
    "if os.path.isfile(PIPELINES_FILEPATH):\n",
    "    with open(PIPELINES_FILEPATH) as f:\n",
    "        PIPELINES = json.load(f)\n",
    "else:\n",
    "    PIPELINES = {}\n",
    "\n",
    "def save_pipelines():\n",
    "    with open(PIPELINES_FILEPATH, 'w') as f:\n",
    "        json.dump(PIPELINES, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d66fd7-22b7-4682-ad27-dfdb3bc1c551",
   "metadata": {},
   "source": [
    "### KFP Custom Component - training data query\n",
    "\n",
    "Details: From `futurama_weekly` pull data between 7/20 - 12/21 (100 gb limit for automl tables). Automatically set testing and validation as follows:\n",
    "    \n",
    "* Train: 2/20-4/21\n",
    "* Validate: 5/21-6/21\n",
    "* Test: 6/21-12/21\n",
    "    \n",
    "Also set `series_id` to be a concat: `concat(category_id, geo_id, term) as series_id`\n",
    "\n",
    "Note this will create a backtest for the test period to understand the effecicacy of the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46e5f2-b27f-4286-98e2-83f11962f217",
   "metadata": {},
   "source": [
    "### Starter component - check source table date for run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0f1d97-61ad-4a31-92ba-88428dd4a61b",
   "metadata": {},
   "source": [
    "#### Detailed Report Custom Component\n",
    "\n",
    "This creates the futurama weekly table with Swivel NLP embeddings (20 float fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff31cb65-ec36-44f3-963c-e9a8dc970a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def create_prediction_dataset_term_level(\n",
    "      target_table: str,\n",
    "      source_table_uri: str,\n",
    "      train_st: str,\n",
    "      train_end: str,\n",
    "      valid_st: str,\n",
    "      valid_end: str,\n",
    "      subcat_id: int = 10047,\n",
    "      override: str = 'False',\n",
    "      project_id: str = 'cpg-cdp'\n",
    "    ) -> NamedTuple('Outputs', [('training_data_table_uri', str)]):\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    " \n",
    "    override = bool(override)\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"CREATE TEMPORARY FUNCTION arr_to_input_20(arr ARRAY<FLOAT64>)\n",
    "        RETURNS \n",
    "        STRUCT<p1 FLOAT64, p2 FLOAT64, p3 FLOAT64, p4 FLOAT64,\n",
    "               p5 FLOAT64, p6 FLOAT64, p7 FLOAT64, p8 FLOAT64, \n",
    "               p9 FLOAT64, p10 FLOAT64, p11 FLOAT64, p12 FLOAT64, \n",
    "               p13 FLOAT64, p14 FLOAT64, p15 FLOAT64, p16 FLOAT64,\n",
    "               p17 FLOAT64, p18 FLOAT64, p19 FLOAT64, p20 FLOAT64>\n",
    "        AS (\n",
    "        STRUCT(\n",
    "            arr[OFFSET(0)]\n",
    "            , arr[OFFSET(1)]\n",
    "            , arr[OFFSET(2)]\n",
    "            , arr[OFFSET(3)]\n",
    "            , arr[OFFSET(4)]\n",
    "            , arr[OFFSET(5)]\n",
    "            , arr[OFFSET(6)]\n",
    "            , arr[OFFSET(7)]\n",
    "            , arr[OFFSET(8)]\n",
    "            , arr[OFFSET(9)]\n",
    "            , arr[OFFSET(10)]\n",
    "            , arr[OFFSET(11)]\n",
    "            , arr[OFFSET(12)]\n",
    "            , arr[OFFSET(13)]\n",
    "            , arr[OFFSET(14)]\n",
    "            , arr[OFFSET(15)]\n",
    "            , arr[OFFSET(16)]\n",
    "            , arr[OFFSET(17)]\n",
    "            , arr[OFFSET(18)]\n",
    "            , arr[OFFSET(19)]    \n",
    "        ));\n",
    "\n",
    "\n",
    "        CREATE OR REPLACE TABLE `{target_table}` as (\n",
    "            SELECT * except(output_0), case when date between \"{train_st}\" and \"{train_end}\" then 'TRAIN'\n",
    "                  when date between \"{valid_st}\" and \"{valid_end}\" then 'VALIDATE'\n",
    "                 else 'TEST' end as split_col,\n",
    "            arr_to_input_20(output_0) as embed\n",
    "        FROM ML.PREDICT(MODEL trendspotting.swivel_text_embed,(\n",
    "          SELECT date, geo_id, term AS sentences, category_rank, concat( term, geo_id) as series_id\n",
    "          FROM `{source_table_uri}`\n",
    "        ))\n",
    "        )\n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'{target_table}',\n",
    "    )\n",
    "# --- where subcategory_id = {subcat_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f26d0a-e93d-48c8-af3d-214ba1b0992a",
   "metadata": {},
   "source": [
    "### Preparing data for k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4432e7cd-92e1-493b-b989-153202b3ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def prep_forecast_term_level(\n",
    "    source_table: str,\n",
    "    target_table: str,\n",
    "    override: str = 'False',\n",
    "    project_id: str = 'cpg-cdp'\n",
    "    ) -> NamedTuple('Outputs', [('term_train_table', str)]):\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"\n",
    "            CREATE OR REPLACE TABLE `{target_table}` as (\n",
    "        SELECT * except(embed), \n",
    "        embed.p1 as emb1, \n",
    "        embed.p2 as emb2,\n",
    "        embed.p3 as emb3,\n",
    "        embed.p4 as emb4,\n",
    "        embed.p5 as emb5,\n",
    "        embed.p6 as emb6,\n",
    "        embed.p7 as emb7,\n",
    "        embed.p8 as emb8,\n",
    "        embed.p9 as emb9,\n",
    "        embed.p10 as emb10,\n",
    "        embed.p11 as emb11,\n",
    "        embed.p12 as emb12,\n",
    "        embed.p13 as emb13,\n",
    "        embed.p14 as emb14,\n",
    "        embed.p15 as emb15,\n",
    "        embed.p16 as emb16,\n",
    "        embed.p17 as emb17,\n",
    "        embed.p18 as emb18,\n",
    "        embed.p19 as emb19,\n",
    "        embed.p20 as emb20\n",
    "\n",
    "        FROM `{source_table}` )\n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'bq://{target_table}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09854d77-5c2f-4066-a3f7-ade727c3b719",
   "metadata": {},
   "source": [
    "### Produce top-mover table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "300c1930-bea4-445c-8904-e5e9e354aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def create_top_mover_table(\n",
    "    source_table: str,\n",
    "    target_table: str,\n",
    "    predict_on_dt: str, #uses the last validation date,\n",
    "    six_month_dt: str,\n",
    "    trained_model: Input[Artifact],\n",
    "    top_n_results: int,\n",
    "    override: str = 'False',\n",
    "    project_id: str = 'cpg-cdp'\n",
    "    ) -> NamedTuple('Outputs', [('term_train_table', str)]):\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    "    \n",
    "    source_table_no_bq = source_table.strip('bq://')\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"\n",
    "            CREATE OR REPLACE TABLE {target_table} as (\n",
    "    select * from\n",
    "      (with six_mo_val as (select *, predicted_category_rank.value as six_mo_forecast from `{source_table_no_bq}` \n",
    "        where predicted_on_date = '{predict_on_dt}' and date = '{six_month_dt}'),\n",
    "         geo_id as (select distinct geo_id, geo_name from `cpg-cdp.trendspotting.futurama_weekly`)\n",
    "    SELECT a.date, \n",
    "       geo_id.geo_name, \n",
    "       a.sentences, \n",
    "       cast(a.category_rank as int64) as current_rank, \n",
    "       cast(a.category_rank as int64) - b.six_mo_forecast as six_delta_rank,\n",
    "       cast(b.category_rank as int64) as six_mo_rank, \n",
    "       six_mo_forecast\n",
    "      FROM `{source_table_no_bq}` a INNER JOIN \n",
    "       six_mo_val b on a.series_id = b.series_id \n",
    "       inner join \n",
    "       geo_id on cast(a.geo_id as int64) = geo_id.geo_id\n",
    "      WHERE a.date = '{predict_on_dt}'\n",
    "      ) where current_rank > 500 and six_mo_forecast < 600 order by six_delta_rank desc limit {top_n_results} \n",
    ")\n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'{target_table}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8a6224-65e4-40d1-bc98-06995d1d8a05",
   "metadata": {},
   "source": [
    "## Top level report\n",
    "\n",
    "This component takes futurama weekly, adds the NLP features plus applies the trained 100 cluster model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5643fd6-2853-4ff4-bde8-2b85f18ac006",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def nlp_featurize_and_cluster(\n",
    "    source_table: str,\n",
    "    target_table: str,\n",
    "    train_st: str,\n",
    "    train_end: str,\n",
    "    subcat_id: int = 10047,\n",
    "    override: str = 'False',\n",
    "    project_id: str = 'cpg-cdp'\n",
    "    ) -> NamedTuple('Outputs', [('term_cluster_table', str)]):\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    "    \n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"\n",
    "            CREATE TEMPORARY FUNCTION arr_to_input_20(arr ARRAY<FLOAT64>)\n",
    "            RETURNS \n",
    "            STRUCT<p1 FLOAT64, p2 FLOAT64, p3 FLOAT64, p4 FLOAT64,\n",
    "                   p5 FLOAT64, p6 FLOAT64, p7 FLOAT64, p8 FLOAT64, \n",
    "                   p9 FLOAT64, p10 FLOAT64, p11 FLOAT64, p12 FLOAT64, \n",
    "                   p13 FLOAT64, p14 FLOAT64, p15 FLOAT64, p16 FLOAT64,\n",
    "                   p17 FLOAT64, p18 FLOAT64, p19 FLOAT64, p20 FLOAT64>\n",
    "            AS (\n",
    "            STRUCT(\n",
    "                arr[OFFSET(0)]\n",
    "                , arr[OFFSET(1)]\n",
    "                , arr[OFFSET(2)]\n",
    "                , arr[OFFSET(3)]\n",
    "                , arr[OFFSET(4)]\n",
    "                , arr[OFFSET(5)]\n",
    "                , arr[OFFSET(6)]\n",
    "                , arr[OFFSET(7)]\n",
    "                , arr[OFFSET(8)]\n",
    "                , arr[OFFSET(9)]\n",
    "                , arr[OFFSET(10)]\n",
    "                , arr[OFFSET(11)]\n",
    "                , arr[OFFSET(12)]\n",
    "                , arr[OFFSET(13)]\n",
    "                , arr[OFFSET(14)]\n",
    "                , arr[OFFSET(15)]\n",
    "                , arr[OFFSET(16)]\n",
    "                , arr[OFFSET(17)]\n",
    "                , arr[OFFSET(18)]\n",
    "                , arr[OFFSET(19)]    \n",
    "            ));\n",
    "\n",
    "            CREATE OR REPLACE TABLE {target_table} as ( #\n",
    "                select * \n",
    "                from ML.PREDICT(MODEL trendspotting.embed_clustering_100, (\n",
    "                    select *, arr_to_input_20(output_0) AS comments_embed from \n",
    "                        ML.PREDICT(MODEL trendspotting.swivel_text_embed,(\n",
    "                      SELECT date, geo_name, term AS sentences, volume\n",
    "                      FROM `{source_table}`\n",
    "                      WHERE date >= '{train_st}' \n",
    "                    ))\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'{target_table}',\n",
    "    )\n",
    "# and category_id = {subcat_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853aea81-7902-4102-88f6-098a198036e8",
   "metadata": {},
   "source": [
    "#### Creation of aggregated cluster-level data\n",
    "Used in the cluster forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d93180e3-89f0-4353-983d-61f326daf0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def aggregate_clusters(\n",
    "    source_table: str,\n",
    "    target_table: str,\n",
    "    train_st: str,\n",
    "    train_end: str,\n",
    "    valid_st: str,\n",
    "    valid_end: str,\n",
    "    override: str = 'False',\n",
    "    project_id: str = 'cpg-cdp'\n",
    "    ) -> NamedTuple('Outputs', [('term_cluster_agg_table', str)]):\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    "    \n",
    "    source_table_no_bq = source_table.strip('bq://')\n",
    "    \n",
    "    target_bq_table = 'bq://' + target_table\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"\n",
    "            CREATE OR REPLACE TABLE {target_table} as (\n",
    "            with centroids as (select * from \n",
    "            (SELECT\n",
    "            centroid_id, feature, numerical_value\n",
    "            FROM\n",
    "              ML.CENTROIDS(MODEL `trendspotting.embed_clustering_100`)\n",
    "            )\n",
    "            PIVOT(avg(numerical_value) for feature in ('comments_embed_p1',\n",
    "            'comments_embed_p2',\n",
    "            'comments_embed_p3',\n",
    "            'comments_embed_p4',\n",
    "            'comments_embed_p5',\n",
    "            'comments_embed_p6',\n",
    "            'comments_embed_p7',\n",
    "            'comments_embed_p8',\n",
    "            'comments_embed_p9',\n",
    "            'comments_embed_p10',\n",
    "            'comments_embed_p11',\n",
    "            'comments_embed_p12',\n",
    "            'comments_embed_p13',\n",
    "            'comments_embed_p14',\n",
    "            'comments_embed_p15',\n",
    "            'comments_embed_p16',\n",
    "            'comments_embed_p17',\n",
    "            'comments_embed_p18',\n",
    "            'comments_embed_p19',\n",
    "            'comments_embed_p20'))\n",
    "                              )\n",
    "            select volume, date, b.*,\n",
    "            case when date between '{train_st}' and  '{train_end}' then 'TRAIN'\n",
    "                      when date between '{valid_st}' and '{valid_end}' then 'VALIDATE'\n",
    "                     else 'TEST' end as split_col\n",
    "            from (\n",
    "                select sum(volume) as volume, date, centroid_id \n",
    "                from {source_table} group by date, centroid_id\n",
    "            ) a\n",
    "            inner join centroids b on a.centroid_id = b.centroid_id\n",
    "            )\n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'{target_bq_table}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6138f3d-7d16-46c5-aa34-ef66bc40aac9",
   "metadata": {},
   "source": [
    "### Feature Specs for forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca3afee2-470b-445d-8360-1cbf89b3d44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp.v2.components.types.type_utils import artifact_types\n",
    "\n",
    "COLUMN_TRANSFORMS_CLUSTER = [\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"volume\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"timestamp\": {\n",
    "      \"columnName\": \"date\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p1\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p2\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p3\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p4\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p5\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p6\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p7\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p8\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p9\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p10\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p11\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p12\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p13\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p14\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p15\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p16\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p17\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p18\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p19\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"comments_embed_p20\"\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "COLUMN_TRANSFORMATIONS = [\n",
    "  {\n",
    "    \"timestamp\": {\n",
    "      \"columnName\": \"date\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"categorical\": {\n",
    "      \"columnName\": \"geo_id\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"text\": {\n",
    "      \"columnName\": \"sentences\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"category_rank\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb1\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb2\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb3\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb4\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb5\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb6\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb7\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb8\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb9\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb10\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb11\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb12\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb13\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb14\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb15\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb16\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb17\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb18\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb19\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb20\"\n",
    "    }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9cfd3a-e4b3-4de6-9486-901b6ab7583f",
   "metadata": {},
   "source": [
    "### Pipeline \n",
    "\n",
    "Uses custom components, also uses reusable vertex components for creating the training dataset and training the forecast models\n",
    "\n",
    "Notice the output for testing in BQ is set by `target_table`, assigned to `export_evaluated_data_items_bigquery_destination_uri`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b359e68f-d95a-4a57-ad27-5b61b4c70974",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMEK = 'projects/cpg-cdp/locations/us-central1/keyRings/central-bq-cmek/cryptoKeys/bq-vertex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61b9d896-c952-40b1-ba3b-4b14a973fcbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERSION = 'test'\n",
    "PIPELINE_TAG = 'trendspotting-pipeline' # <--- TODO; optionally name pipeline\n",
    "@kfp.v2.dsl.pipeline(\n",
    "  name=f'{VERSION}-{PIPELINE_TAG}'.replace('_', '-'),\n",
    "        pipeline_root=PIPELINES_FILEPATH,\n",
    "\n",
    ")\n",
    "def pipeline(\n",
    "    vertex_project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    ds_display_name_terms: str,\n",
    "    ds_display_name_cluster: str,\n",
    "    train_st: str,\n",
    "    train_end: str,\n",
    "    valid_st: str,\n",
    "    valid_end: str,\n",
    "    predict_on_dt: str,\n",
    "    override: str,\n",
    "    k_means_name: str,\n",
    "    n_clusters: int,\n",
    "    top_n_results: int,\n",
    "    six_month_dt: str,\n",
    "    source_table: str ,\n",
    "    target_term_forecast_table: str ,\n",
    "    target_cluster_forecast_table: str ,\n",
    "    budget_milli_node_hours: int,\n",
    "    budget_milli_node_hours_cluster: int,\n",
    "    context_window: int,\n",
    "    forecast_horizon: int,\n",
    "    top_movers_target_table: str,\n",
    "):\n",
    "\n",
    "\n",
    "    # get_data_source = gcp_aip_bq.BigqueryQueryJobOp(\n",
    "    #   project = 'cpg-cdp',\n",
    "    #   location = 'US',\n",
    "    #   query = f\"\"\"select distinct date from {source_table}\"\"\",\n",
    "    #     # encryption_spec_key_name=CMEK\n",
    "    # )\n",
    "    \n",
    "    embed_terms = create_prediction_dataset_term_level(\n",
    "      target_table = 'cpg-cdp.trendspotting.futurama_weekly_embed',\n",
    "      source_table_uri = source_table,\n",
    "      train_st = train_st,\n",
    "      train_end = train_end,\n",
    "      valid_st = valid_st,\n",
    "      valid_end = valid_end,\n",
    "    ) #-> NamedTuple('Outputs', [('training_data_table_uri', str)])j\n",
    "    \n",
    "    fix_embed = prep_forecast_term_level(\n",
    "        source_table = embed_terms.outputs['training_data_table_uri'],\n",
    "        target_table = 'cpg-cdp.trendspotting.futurama_weekly_embed_aml_pl',\n",
    "        )# -> NamedTuple('Outputs', [('term_train_table', str)]):\n",
    "\n",
    "\n",
    "    time_series_dataset_create_op = gcc_aip.TimeSeriesDatasetCreateOp(\n",
    "        display_name=ds_display_name_terms, \n",
    "        bq_source=fix_embed.outputs['term_train_table'],\n",
    "        project=vertex_project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    term_forecasting_op = gcc_aip.AutoMLForecastingTrainingJobRunOp(\n",
    "        display_name=f'train-point-forecast-futurama',\n",
    "        model_display_name='point-forecast-futurama',\n",
    "        dataset=time_series_dataset_create_op.outputs['dataset'],\n",
    "        context_window=context_window,\n",
    "        forecast_horizon=forecast_horizon,\n",
    "        budget_milli_node_hours=budget_milli_node_hours,\n",
    "        project=vertex_project,\n",
    "        location=location,\n",
    "        export_evaluated_data_items=True,\n",
    "        export_evaluated_data_items_override_destination=True,\n",
    "        target_column='category_rank',\n",
    "        time_column='date',\n",
    "        time_series_identifier_column='series_id',\n",
    "        time_series_attribute_columns=['geo_name', 'geo_id', 'category_id', 'term', \n",
    "                                      'emb1', 'emb2', 'emb3', 'emb4', 'emb5', 'emb6',\n",
    "                                      'emb7', 'emb8', 'emb9', 'emb10', 'emb11', 'emb12',\n",
    "                                      'emb13', 'emb14', 'emb15', 'emb16', 'emb17', 'emb18', \n",
    "                                      'emb19', 'emb20', 'sentences'],\n",
    "        unavailable_at_forecast_columns=['category_rank'],\n",
    "        available_at_forecast_columns=['date'],\n",
    "        data_granularity_unit='week',\n",
    "        data_granularity_count=1,\n",
    "        predefined_split_column_name= 'split_col', \n",
    "        optimization_objective='minimize-rmse',\n",
    "        column_transformations=COLUMN_TRANSFORMATIONS,\n",
    "        export_evaluated_data_items_bigquery_destination_uri = target_term_forecast_table, # must be format:``bq://<project_id>:<dataset_id>:<table>``\n",
    "    )\n",
    "    \n",
    "    top_movers_data_op = create_top_mover_table(source_table = target_term_forecast_table,\n",
    "    target_table = top_movers_target_table,\n",
    "        predict_on_dt = predict_on_dt, \n",
    "        six_month_dt = six_month_dt,\n",
    "        trained_model = term_forecasting_op.outputs['model'],\n",
    "        top_n_results = top_n_results,\n",
    "        ) #-> NamedTuple('Outputs', [('term_train_table', str)]):\n",
    "    \n",
    "    \n",
    "    #HIGH LEVEL REPORT PIPELINE STARTS HERE\n",
    "    \n",
    "    #######################################\n",
    "    create_cluster_terms_op = nlp_featurize_and_cluster(\n",
    "        source_table = source_table,\n",
    "        target_table = \"cpg-cdp.trendspotting.futurama_weekly_embed_cluster_100\",\n",
    "        train_st = train_st,\n",
    "        train_end = train_end,\n",
    "        )# -> NamedTuple('Outputs', [('term_cluster_table', str)]):\n",
    "\n",
    "    \n",
    "    aggregate_cluster_op = aggregate_clusters(\n",
    "        source_table = create_cluster_terms_op.outputs['term_cluster_table'],\n",
    "        target_table = \"cpg-cdp.trendspotting.futurama_weekly_embed_cluster_agg_100\",\n",
    "        train_st = train_st,\n",
    "        train_end = train_end,\n",
    "        valid_st = valid_st,\n",
    "        valid_end = valid_end,\n",
    "        )# -> NamedTuple('Outputs', [('term_cluster_agg_table', str)]):\n",
    "    \n",
    "    \n",
    "    #create training ds in vertex\n",
    "    time_series_dataset_create_op_high_level = gcc_aip.TimeSeriesDatasetCreateOp(\n",
    "        display_name=ds_display_name_cluster, \n",
    "        bq_source=aggregate_cluster_op.outputs['term_cluster_agg_table'],\n",
    "        project=vertex_project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    term_forecasting_op = gcc_aip.AutoMLForecastingTrainingJobRunOp(\n",
    "        display_name=f'train-cluster-forecast-futurama',\n",
    "        model_display_name='cluster-forecast-futurama',\n",
    "        dataset=time_series_dataset_create_op_high_level.outputs['dataset'],\n",
    "        context_window=context_window,\n",
    "        forecast_horizon=forecast_horizon,\n",
    "        budget_milli_node_hours=budget_milli_node_hours_cluster,\n",
    "        project=vertex_project,\n",
    "        location=location,\n",
    "        export_evaluated_data_items=True,\n",
    "        export_evaluated_data_items_override_destination=True,\n",
    "        target_column='volume',\n",
    "        time_column='date',\n",
    "        time_series_identifier_column='centroid_id',\n",
    "        time_series_attribute_columns=['comments_embed_p1', 'comments_embed_p2', 'comments_embed_p3', 'comments_embed_p4', 'comments_embed_p5', 'comments_embed_p6',\n",
    "                                      'comments_embed_p7', 'comments_embed_p8', 'comments_embed_p9', 'comments_embed_p10', 'comments_embed_p11', 'comments_embed_p12',\n",
    "                                      'comments_embed_p13', 'comments_embed_p14', 'comments_embed_p15', 'comments_embed_p16', 'comments_embed_p17', 'comments_embed_p18', \n",
    "                                      'comments_embed_p19', 'comments_embed_p20'],\n",
    "        unavailable_at_forecast_columns=['volume'],\n",
    "        available_at_forecast_columns=['date'],\n",
    "        data_granularity_unit='week',\n",
    "        data_granularity_count=1,\n",
    "        predefined_split_column_name= 'split_col', \n",
    "        optimization_objective='minimize-rmse',\n",
    "        column_transformations=COLUMN_TRANSFORMS_CLUSTER,\n",
    "        export_evaluated_data_items_bigquery_destination_uri = target_cluster_forecast_table, # must be format:``bq://<project_id>:<dataset_id>:<table>``\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8d9ec46-05d3-4dba-a935-c58026a5e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='trendspotting.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f6a37-e374-4570-b462-fd9d6b93691f",
   "metadata": {},
   "source": [
    "### Set parameters for pipeline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a112290-eb83-48b6-8006-fdd244a02679",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'cpg-cdp' # <--- TODO: If not set\n",
    "LOCATION = 'us-central1' # <--- TODO: If not set\n",
    "SERVICE_ACCOUNT = 'vertex-pipelines@cpg-cdp.iam.gserviceaccount.com' , # <--- TODO: Change This if needed\n",
    "N_CLUSTERS = 100\n",
    "K_MEANS_MODEL_NAME = f\"trendspotting_{N_CLUSTERS}_rmse_RB\"\n",
    "\n",
    "\n",
    "# BQ dataset for source data source\n",
    "SOURCE_DATA = 'futurama_weekly_energy_drinks'\n",
    "TOP_N_RESULTS = 500\n",
    "# TODO: Forecasting Configuration:\n",
    "HISTORY_WINDOW_n = 52 #  {type: 'integer'} # context_window\n",
    "FORECAST_HORIZON = 52 #  {type: 'integer'} \n",
    "BUDGET_MILLI_NODE_HOURS = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1bc9f7ac-9937-4f1a-baa4-643d6e688648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b46db-4137-4ab6-8c68-b9b1d4153b55",
   "metadata": {},
   "source": [
    "### Run the pipeline\n",
    "Follow the link to see the exectution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87946ac5-3fde-4251-b5bd-8e26e184832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/939655404703/locations/us-central1/pipelineJobs/test-trendspotting-pipeline-20220506184441\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/939655404703/locations/us-central1/pipelineJobs/test-trendspotting-pipeline-20220506184441')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/test-trendspotting-pipeline-20220506184441?project=939655404703\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "PIPELINE_PARAMETERS = {\n",
    "    'vertex_project': PROJECT_ID,\n",
    "    'location': LOCATION,\n",
    "    'version': VERSION,\n",
    "    'train_st': '2017-09-03',\n",
    "    'train_end': '2020-12-31',\n",
    "    'valid_st': '2021-01-01',\n",
    "    'valid_end': '2021-12-31',\n",
    "    'predict_on_dt': '2022-01-01',\n",
    "    'six_month_dt': '2022-05-01',\n",
    "    'context_window': HISTORY_WINDOW_n,\n",
    "    'forecast_horizon': FORECAST_HORIZON,\n",
    "    'budget_milli_node_hours': BUDGET_MILLI_NODE_HOURS,\n",
    "    'ds_display_name_terms': 'futurama-term-forecasts-RED_BULL',\n",
    "    'ds_display_name_cluster': 'futurama-clusters-RED_BULL',\n",
    "    'k_means_name': K_MEANS_MODEL_NAME,\n",
    "    'n_clusters': N_CLUSTERS,\n",
    "    'top_n_results': TOP_N_RESULTS,\n",
    "    'override' : 'false',\n",
    "    'target_term_forecast_table' : 'bq://cpg-cdp.trendspotting.predict_c52_p52_embed_pl_RB',\n",
    "    'source_table' : 'cpg-cdp.trendspotting.futurama_weekly_energy_drinks',\n",
    "    'target_term_forecast_table': 'cpg-cdp.trendspotting.predict_RB',\n",
    "    'target_cluster_forecast_table': 'cpg-cdp.trendspotting.predict_cluster_RB',\n",
    "    'top_movers_target_table': 'cpg-cdp.trendspotting.top_movers_pl_RB',\n",
    "    'budget_milli_node_hours': 8000,\n",
    "    'budget_milli_node_hours_cluster': 8000,\n",
    "    }\n",
    "\n",
    "job = aiplatform.PipelineJob(display_name = 'trendspotting_REDBULL',\n",
    "                             template_path = 'trendspotting.json',\n",
    "                             pipeline_root = PIPELINES_FILEPATH,\n",
    "                             parameter_values = PIPELINE_PARAMETERS,\n",
    "                             project = PROJECT_ID,\n",
    "                             location = LOCATION)\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc706d8-c491-4bfe-b979-0eff321957aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f4828d-4ecd-4228-ab0d-b0e31037a001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
