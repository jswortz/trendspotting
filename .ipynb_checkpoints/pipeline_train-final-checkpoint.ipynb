{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e4af0c-18f3-43f4-b418-17b48f156ef8",
   "metadata": {},
   "source": [
    "# Trendspotting POC\n",
    "\n",
    "Goal of this notebook is to\n",
    "* Load signals data into a managed vertex dataset for time series forecasting\n",
    "* Create a forecast prediction model for each term, geo and category combination\n",
    "* Project the forecasts on a holdout set of data to assess performance and trends\n",
    "* Clean up results of test predictions\n",
    "* Cluster test predictions\n",
    "* Create dashboard for backtesting\n",
    "\n",
    "[Source Control Link](https://source.cloud.google.com/cpg-cdp/trendspotting/+/master:pipeline_train.ipynb)\n",
    "\n",
    "When run - the piepline will look something like this:\n",
    "\n",
    "![pipeline example](img/pipeline_example.png)\n",
    "\n",
    "Todo: Integration of ingredients, flagging of trends\n",
    "\n",
    "## Install packages, create bucket (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5999fd54-5659-406e-87f5-b0778db565ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # New\n",
    "# ! pip3 install -U google-cloud-storage --user\n",
    "# # ! pip3 install $USER kfp google-cloud-pipeline-components --upgrade\n",
    "# !git clone https://github.com/kubeflow/pipelines.git\n",
    "# !pip install pipelines/components/google-cloud/.\n",
    "# !pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f4daa105-58de-4046-be85-779f845936e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil mb -l us-central1 gs://trendspotting-pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15945c-b978-45c4-9ecc-87e17c4097b6",
   "metadata": {},
   "source": [
    "### Import libs and types for KFP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "00b2a410-def8-43de-aa41-2ed9efe75d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from google import auth\n",
    "from google.api_core import exceptions as google_exceptions\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.experimental import forecasting as gcc_aip_forecasting\n",
    "import google.cloud.aiplatform\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "from typing import Dict, List, Optional, Sequence, Tuple, Union\n",
    "from kfp.v2.dsl import Artifact\n",
    "from kfp.v2.dsl import Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a95fbc67-a62b-42f2-a756-a6e304bf582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'cpg-cdp'\n",
    "LOCATION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b675de8f-00f9-4d2f-9d5c-73e3d9e78683",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINES = {}\n",
    "\n",
    "PIPELINES_FILEPATH = 'gs://trendspotting-pipeline' # <--- TODO: CHANGE THIS; can be blank json file\n",
    "\n",
    "if os.path.isfile(PIPELINES_FILEPATH):\n",
    "    with open(PIPELINES_FILEPATH) as f:\n",
    "        PIPELINES = json.load(f)\n",
    "else:\n",
    "    PIPELINES = {}\n",
    "\n",
    "def save_pipelines():\n",
    "    with open(PIPELINES_FILEPATH, 'w') as f:\n",
    "        json.dump(PIPELINES, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d66fd7-22b7-4682-ad27-dfdb3bc1c551",
   "metadata": {},
   "source": [
    "### KFP Custom Component - training data query\n",
    "\n",
    "Details: From `futurama_weekly` pull data between 7/20 - 12/21 (100 gb limit for automl tables). Automatically set testing and validation as follows:\n",
    "    \n",
    "* Train: 2/20-4/21\n",
    "* Validate: 5/21-6/21\n",
    "* Test: 6/21-12/21\n",
    "    \n",
    "Also set `series_id` to be a concat: `concat(category_id, geo_id, term) as series_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ff31cb65-ec36-44f3-963c-e9a8dc970a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def create_prediction_dataset_term_level(\n",
    "      target_table: str,\n",
    "      source_table_uri: str,\n",
    "      train_st: str,\n",
    "      train_end: str,\n",
    "      valid_st: str,\n",
    "      valid_end: str,\n",
    "      subcat_id: int = 10047,\n",
    "      override: str = 'False',\n",
    "      project_id: str = 'cpg-cdp'\n",
    "    ) -> NamedTuple('Outputs', [('training_data_table_uri', str)]):\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    " \n",
    "    override = bool(override)\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"CREATE TEMPORARY FUNCTION arr_to_input_20(arr ARRAY<FLOAT64>)\n",
    "        RETURNS \n",
    "        STRUCT<p1 FLOAT64, p2 FLOAT64, p3 FLOAT64, p4 FLOAT64,\n",
    "               p5 FLOAT64, p6 FLOAT64, p7 FLOAT64, p8 FLOAT64, \n",
    "               p9 FLOAT64, p10 FLOAT64, p11 FLOAT64, p12 FLOAT64, \n",
    "               p13 FLOAT64, p14 FLOAT64, p15 FLOAT64, p16 FLOAT64,\n",
    "               p17 FLOAT64, p18 FLOAT64, p19 FLOAT64, p20 FLOAT64>\n",
    "        AS (\n",
    "        STRUCT(\n",
    "            arr[OFFSET(0)]\n",
    "            , arr[OFFSET(1)]\n",
    "            , arr[OFFSET(2)]\n",
    "            , arr[OFFSET(3)]\n",
    "            , arr[OFFSET(4)]\n",
    "            , arr[OFFSET(5)]\n",
    "            , arr[OFFSET(6)]\n",
    "            , arr[OFFSET(7)]\n",
    "            , arr[OFFSET(8)]\n",
    "            , arr[OFFSET(9)]\n",
    "            , arr[OFFSET(10)]\n",
    "            , arr[OFFSET(11)]\n",
    "            , arr[OFFSET(12)]\n",
    "            , arr[OFFSET(13)]\n",
    "            , arr[OFFSET(14)]\n",
    "            , arr[OFFSET(15)]\n",
    "            , arr[OFFSET(16)]\n",
    "            , arr[OFFSET(17)]\n",
    "            , arr[OFFSET(18)]\n",
    "            , arr[OFFSET(19)]    \n",
    "        ));\n",
    "\n",
    "\n",
    "        CREATE OR REPLACE TABLE `{target_table}` as (\n",
    "            SELECT * except(output_0), case when date between \"{train_st}\" and \"{train_end}\" then 'TRAIN'\n",
    "                  when date between \"{valid_st}\" and \"{valid_end}\" then 'VALIDATE'\n",
    "                 else 'TEST' end as split_col,\n",
    "            arr_to_input_20(output_0) as embed\n",
    "        FROM ML.PREDICT(MODEL trendspotting.swivel_text_embed,(\n",
    "          SELECT date, geo_id, term AS sentences, category_rank, concat( term, geo_id) as series_id\n",
    "          FROM `{source_table_uri}` where subcategory_id = {subcat_id}\n",
    "        ))\n",
    "        )\n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'{target_table}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f26d0a-e93d-48c8-af3d-214ba1b0992a",
   "metadata": {},
   "source": [
    "### Preparing data for k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4432e7cd-92e1-493b-b989-153202b3ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def prep_forecast_term_level(\n",
    "    source_table: str,\n",
    "    target_table: str,\n",
    "    override: str = 'False',\n",
    "    project_id: str = 'cpg-cdp'\n",
    "    ) -> NamedTuple('Outputs', [('term_train_table', str)]):\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"\n",
    "            CREATE OR REPLACE TABLE `{target_table}` as (\n",
    "        SELECT * except(embed), \n",
    "        embed.p1 as emb1, \n",
    "        embed.p2 as emb2,\n",
    "        embed.p3 as emb3,\n",
    "        embed.p4 as emb4,\n",
    "        embed.p5 as emb5,\n",
    "        embed.p6 as emb6,\n",
    "        embed.p7 as emb7,\n",
    "        embed.p8 as emb8,\n",
    "        embed.p9 as emb9,\n",
    "        embed.p10 as emb10,\n",
    "        embed.p11 as emb11,\n",
    "        embed.p12 as emb12,\n",
    "        embed.p13 as emb13,\n",
    "        embed.p14 as emb14,\n",
    "        embed.p15 as emb15,\n",
    "        embed.p16 as emb16,\n",
    "        embed.p17 as emb17,\n",
    "        embed.p18 as emb18,\n",
    "        embed.p19 as emb19,\n",
    "        embed.p20 as emb20\n",
    "\n",
    "        FROM `{source_table}` )\n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'bq://{target_table}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09854d77-5c2f-4066-a3f7-ade727c3b719",
   "metadata": {},
   "source": [
    "### Produce top-mover table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "300c1930-bea4-445c-8904-e5e9e354aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def create_top_mover_table(\n",
    "    source_table: str,\n",
    "    target_table: str,\n",
    "    predict_on_dt: str, #uses the last validation date,\n",
    "    six_month_dt: str,\n",
    "    trained_model: Input[Artifact],\n",
    "    top_n_results: int,\n",
    "    override: str = 'False',\n",
    "    project_id: str = 'cpg-cdp'\n",
    "    ) -> NamedTuple('Outputs', [('term_train_table', str)]):\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    "    \n",
    "    source_table_no_bq = source_table.strip('bq://')\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"\n",
    "            CREATE OR REPLACE TABLE {target_table} as (\n",
    "    select * from\n",
    "      (with six_mo_val as (select *, predicted_category_rank.value as six_mo_forecast from `{source_table_no_bq}` \n",
    "        where predicted_on_date = '{predict_on_dt}' and date = '{six_month_dt}'),\n",
    "         geo_id as (select distinct geo_id, geo_name from `cpg-cdp.trendspotting.futurama_weekly`)\n",
    "    SELECT a.date, \n",
    "       geo_id.geo_name, \n",
    "       a.sentences, \n",
    "       cast(a.category_rank as int64) as current_rank, \n",
    "       cast(a.category_rank as int64) - b.six_mo_forecast as six_delta_rank,\n",
    "       cast(b.category_rank as int64) as six_mo_rank, \n",
    "       six_mo_forecast\n",
    "      FROM `{source_table_no_bq}` a INNER JOIN \n",
    "       six_mo_val b on a.series_id = b.series_id \n",
    "       inner join \n",
    "       geo_id on cast(a.geo_id as int64) = geo_id.geo_id\n",
    "      WHERE a.date = '{predict_on_dt}'\n",
    "      ) where current_rank > 500 and six_mo_forecast < 600 order by six_delta_rank desc limit {top_n_results} \n",
    ")\n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'{target_table}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ca3afee2-470b-445d-8360-1cbf89b3d44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "VERSION = 'poc_rmse'\n",
    "rmse_model_version = 'poc_rmse'\n",
    "\n",
    "COLUMN_TRANSFORMATIONS = [\n",
    "  {\n",
    "    \"timestamp\": {\n",
    "      \"columnName\": \"date\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"categorical\": {\n",
    "      \"columnName\": \"geo_id\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"text\": {\n",
    "      \"columnName\": \"sentences\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"category_rank\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb1\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb2\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb3\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb4\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb5\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb6\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb7\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb8\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb9\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb10\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb11\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb12\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb13\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb14\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb15\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb16\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb17\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb18\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb19\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"emb20\"\n",
    "    }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9cfd3a-e4b3-4de6-9486-901b6ab7583f",
   "metadata": {},
   "source": [
    "### Pipeline \n",
    "\n",
    "Uses custom components, also uses reusable vertex components for creating the training dataset and training the forecast models\n",
    "\n",
    "Notice the output for testing in BQ is set by `target_table`, assigned to `export_evaluated_data_items_bigquery_destination_uri`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "61b9d896-c952-40b1-ba3b-4b14a973fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_TAG = 'trendspotting-pipeline' # <--- TODO; optionally name pipeline\n",
    "@kfp.v2.dsl.pipeline(\n",
    "  name=f'{VERSION}-{PIPELINE_TAG}'.replace('_', '-'),\n",
    "        pipeline_root=PIPELINES_FILEPATH,\n",
    "\n",
    ")\n",
    "def pipeline(\n",
    "    vertex_project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    ds_display_name_terms: str,\n",
    "    train_st: str,\n",
    "    train_end: str,\n",
    "    valid_st: str,\n",
    "    valid_end: str,\n",
    "    predict_on_dt: str,\n",
    "    context_window: int,\n",
    "    forecast_horizon: int,\n",
    "    override: str,\n",
    "    k_means_name: str,\n",
    "    n_clusters: int,\n",
    "    top_n_results: int,\n",
    "    six_month_dt: str,\n",
    "    source_table: str = 'cpg-cdp.trendspotting.futurama_weekly',\n",
    "    target_term_forecast_table: str = 'cpg-cdp.trendspotting.predict_c52_p52_embed_pl',\n",
    "    budget_milli_node_hours: int = 1000,\n",
    "):\n",
    "\n",
    "    \n",
    "    embed_terms = create_prediction_dataset_term_level(\n",
    "      target_table = 'cpg-cdp.trendspotting.futurama_weekly_embed',\n",
    "      source_table_uri = source_table,\n",
    "      train_st = train_st,\n",
    "      train_end = train_end,\n",
    "      valid_st = valid_st,\n",
    "      valid_end = valid_end,\n",
    "    ) #-> NamedTuple('Outputs', [('training_data_table_uri', str)])j\n",
    "    \n",
    "    fix_embed = prep_forecast_term_level(\n",
    "        source_table = embed_terms.outputs['training_data_table_uri'],\n",
    "        target_table = 'cpg-cdp.trendspotting.futurama_weekly_embed_aml_pl',\n",
    "        )# -> NamedTuple('Outputs', [('term_train_table', str)]):\n",
    "\n",
    "\n",
    "    time_series_dataset_create_op = gcc_aip.TimeSeriesDatasetCreateOp(\n",
    "        display_name=ds_display_name_terms, \n",
    "        bq_source=fix_embed.outputs['term_train_table'],\n",
    "        project=vertex_project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    term_forecasting_op = gcc_aip_forecasting.ForecastingTrainingWithExperimentsOp(\n",
    "        display_name=f'train-{rmse_model_version}',\n",
    "        model_display_name=rmse_model_version,\n",
    "        dataset=time_series_dataset_create_op.outputs['dataset'],\n",
    "        context_window=context_window,\n",
    "        forecast_horizon=forecast_horizon,\n",
    "        budget_milli_node_hours=budget_milli_node_hours,\n",
    "        project=vertex_project,\n",
    "        location=location,\n",
    "        export_evaluated_data_items=True,\n",
    "        export_evaluated_data_items_override_destination=True,\n",
    "        target_column='category_rank',\n",
    "        time_column='date',\n",
    "        time_series_identifier_column='series_id',\n",
    "        time_series_attribute_columns=['geo_name', 'geo_id', 'category_id', 'term', \n",
    "                                      'emb1', 'emb2', 'emb3', 'emb4', 'emb5', 'emb6',\n",
    "                                      'emb7', 'emb8', 'emb9', 'emb10', 'emb11', 'emb12',\n",
    "                                      'emb13', 'emb14', 'emb15', 'emb16', 'emb17', 'emb18', \n",
    "                                      'emb19', 'emb20', 'sentences'],\n",
    "        unavailable_at_forecast_columns=['category_rank'],\n",
    "        available_at_forecast_columns=['date'],\n",
    "        data_granularity_unit='week',\n",
    "        data_granularity_count=1,\n",
    "        predefined_split_column_name= 'split_col', \n",
    "        optimization_objective='minimize-rmse',\n",
    "        column_transformations=COLUMN_TRANSFORMATIONS,\n",
    "        export_evaluated_data_items_bigquery_destination_uri = target_term_forecast_table, # must be format:``bq://<project_id>:<dataset_id>:<table>``\n",
    "    )\n",
    "    \n",
    "    top_movers_data_op = create_top_mover_table(source_table = target_term_forecast_table,\n",
    "    target_table = 'cpg-cdp.trendspotting.top_movers_pl',\n",
    "        predict_on_dt = predict_on_dt, \n",
    "        six_month_dt = six_month_dt,\n",
    "        trained_model = term_forecasting_op.outputs['model'],\n",
    "        top_n_results = top_n_results,\n",
    "        ) #-> NamedTuple('Outputs', [('term_train_table', str)]):\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d8d9ec46-05d3-4dba-a935-c58026a5e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='trendspotting.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f6a37-e374-4570-b462-fd9d6b93691f",
   "metadata": {},
   "source": [
    "### Set parameters for pipeline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7a112290-eb83-48b6-8006-fdd244a02679",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'cpg-cdp' # <--- TODO: If not set\n",
    "LOCATION = 'us-central1' # <--- TODO: If not set\n",
    "SERVICE_ACCOUNT = 'vertex-pipelines@cpg-cdp.iam.gserviceaccount.com' , # <--- TODO: Change This if needed\n",
    "N_CLUSTERS = 100\n",
    "K_MEANS_MODEL_NAME = f\"trendspotting_{N_CLUSTERS}_rmse\"\n",
    "\n",
    "\n",
    "# BQ dataset for source data source\n",
    "SOURCE_DATA = 'futurama_weekly'\n",
    "TOP_N_RESULTS = 500\n",
    "# TODO: Forecasting Configuration:\n",
    "HISTORY_WINDOW_n = 52 #  {type: 'integer'} # context_window\n",
    "FORECAST_HORIZON = 52 #  {type: 'integer'} \n",
    "BUDGET_MILLI_NODE_HOURS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1bc9f7ac-9937-4f1a-baa4-643d6e688648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b46db-4137-4ab6-8c68-b9b1d4153b55",
   "metadata": {},
   "source": [
    "### Run the pipeline\n",
    "Follow the link to see the exectution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "87946ac5-3fde-4251-b5bd-8e26e184832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/939655404703/locations/us-central1/pipelineJobs/poc-rmse-trendspotting-pipeline-20220304211452\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/939655404703/locations/us-central1/pipelineJobs/poc-rmse-trendspotting-pipeline-20220304211452')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/poc-rmse-trendspotting-pipeline-20220304211452?project=939655404703\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "# vertex_project: str,\n",
    "#     location: str,\n",
    "#     version: str,\n",
    "#     ds_display_name: str,\n",
    "#     train_st: str,\n",
    "#     train_end: str,\n",
    "#     valid_st: str,\n",
    "#     valid_end: str,\n",
    "#     predict_on_dt: str,\n",
    "#     context_window: int,\n",
    "#     forecast_horizon: int,\n",
    "#     override: str,\n",
    "#     k_means_name: str,\n",
    "#     n_clusters: int,\n",
    "#     top_n_results: int,\n",
    "#     six_month_dt: str,\n",
    "#     source_table: str = 'cpg-cdp.trendspotting.futurama_weekly',\n",
    "#     target_term_forecast_table: str = 'cpg-cdp.trendspotting.predict_c52_p52_embed_pl',\n",
    "#     budget_milli_node_hours: int = 1000,\n",
    "PIPELINE_PARAMETERS = {\n",
    "      'vertex_project': PROJECT_ID,\n",
    "      'location': LOCATION,\n",
    "      'version': VERSION,\n",
    "      'train_st': '2019-01-01',\n",
    "      'train_end': '2020-12-31',\n",
    "      'valid_st': '2021-01-01',\n",
    "      'valid_end': '2021-05-31',\n",
    "      'predict_on_dt': '2021-06-06',\n",
    "      'six_month_dt': '2021-12-26',\n",
    "      'context_window': HISTORY_WINDOW_n,\n",
    "      'forecast_horizon': FORECAST_HORIZON,\n",
    "      'budget_milli_node_hours': BUDGET_MILLI_NODE_HOURS,\n",
    "      'ds_display_name_terms': 'futurama-term-forecasts',\n",
    "      'k_means_name': K_MEANS_MODEL_NAME,\n",
    "      'n_clusters': N_CLUSTERS,\n",
    "      'top_n_results': TOP_N_RESULTS,\n",
    "      'override' : 'false',\n",
    "      'target_term_forecast_table' : 'bq://cpg-cdp.trendspotting.predict_c52_p52_embed_pl'\n",
    "    }\n",
    "\n",
    "job = aiplatform.PipelineJob(display_name = 'trendspotting_test',\n",
    "                             template_path = 'trendspotting.json',\n",
    "                             pipeline_root = PIPELINES_FILEPATH,\n",
    "                             parameter_values = PIPELINE_PARAMETERS,\n",
    "                             project = PROJECT_ID,\n",
    "                             location = LOCATION)\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28adba6-e7da-48cf-b9bf-8b1082e7822b",
   "metadata": {},
   "source": [
    "### Link to downstream report\n",
    "[here](https://datastudio.google.com/c/u/0/reporting/7f55644b-679b-4123-b13d-ce6f90fbd436/page/uhSlC/edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b6057-6d8c-4171-8537-edbb4d0bed24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b2ecc-4c70-49a5-a9ca-734ea5487e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999ff06-8366-4be7-a315-76a59e8e65c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf4ab3-9b1b-49b0-a55c-5b6f80fb2848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
