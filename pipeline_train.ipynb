{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e4af0c-18f3-43f4-b418-17b48f156ef8",
   "metadata": {},
   "source": [
    "# Trendspotting POC\n",
    "\n",
    "Goal of this notebook is to\n",
    "* Load signals data into a managed vertex dataset for time series forecasting\n",
    "* Create a forecast prediction model for each term, geo and category combination\n",
    "* Project the forecasts on a holdout set of data to assess performance and trends\n",
    "* Clean up results of test predictions\n",
    "* Cluster test predictions\n",
    "* Create dashboard for backtesting\n",
    "\n",
    "[Source Control Link](https://source.cloud.google.com/cpg-cdp/trendspotting/+/master:pipeline_train.ipynb)\n",
    "\n",
    "When run - the piepline will look something like this:\n",
    "\n",
    "![pipeline example](img/pipeline_example.png)\n",
    "\n",
    "Todo: Integration of ingredients, flagging of trends\n",
    "\n",
    "## Install packages, create bucket (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5999fd54-5659-406e-87f5-b0778db565ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # New\n",
    "# ! pip3 install -U google-cloud-storage --user\n",
    "# # ! pip3 install $USER kfp google-cloud-pipeline-components --upgrade\n",
    "# !git clone https://github.com/kubeflow/pipelines.git\n",
    "# !pip install pipelines/components/google-cloud/.\n",
    "# !pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4daa105-58de-4046-be85-779f845936e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil mb -l us-central1 gs://trendspotting-pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15945c-b978-45c4-9ecc-87e17c4097b6",
   "metadata": {},
   "source": [
    "### Import libs and types for KFP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b2a410-def8-43de-aa41-2ed9efe75d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from google import auth\n",
    "from google.api_core import exceptions as google_exceptions\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.experimental import forecasting as gcc_aip_forecasting\n",
    "import google.cloud.aiplatform\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "from typing import Dict, List, Optional, Sequence, Tuple, Union\n",
    "from kfp.v2.dsl import Artifact\n",
    "from kfp.v2.dsl import Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a95fbc67-a62b-42f2-a756-a6e304bf582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'cgp-cdp'\n",
    "LOCATION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b675de8f-00f9-4d2f-9d5c-73e3d9e78683",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINES = {}\n",
    "\n",
    "PIPELINES_FILEPATH = 'gs://trendspotting-pipeline' # <--- TODO: CHANGE THIS; can be blank json file\n",
    "\n",
    "if os.path.isfile(PIPELINES_FILEPATH):\n",
    "    with open(PIPELINES_FILEPATH) as f:\n",
    "        PIPELINES = json.load(f)\n",
    "else:\n",
    "    PIPELINES = {}\n",
    "\n",
    "def save_pipelines():\n",
    "    with open(PIPELINES_FILEPATH, 'w') as f:\n",
    "        json.dump(PIPELINES, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d66fd7-22b7-4682-ad27-dfdb3bc1c551",
   "metadata": {},
   "source": [
    "### KFP Custom Component - training data query\n",
    "\n",
    "Details: From `futurama_weekly` pull data between 7/20 - 12/21 (100 gb limit for automl tables). Automatically set testing and validation as follows:\n",
    "    \n",
    "* Train: 2/20-4/21\n",
    "* Validate: 5/21-6/21\n",
    "* Test: 6/21-12/21\n",
    "    \n",
    "Also set `series_id` to be a concat: `concat(category_id, geo_id, term) as series_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff31cb65-ec36-44f3-963c-e9a8dc970a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def create_prediction_dataset(\n",
    "      project: str,\n",
    "      dataset: str,\n",
    "      source_table_uri: str,\n",
    "      override: str = 'False',\n",
    "    ) -> NamedTuple('Outputs', [('training_data_table_uri', str)]):\n",
    "    from google.cloud import bigquery\n",
    " \n",
    "    override = bool(override)\n",
    "    bq_client = bigquery.Client(project=project)\n",
    "    combined_preds_forecast_table_name = f'{project}.{dataset}.y5y6_forecast_volume_term'\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"\n",
    "     create table if not exists `{combined_preds_forecast_table_name}` as (\n",
    "         with raw_data as (\n",
    "         SELECT *, concat(category_id, geo_id, term) as series_id,\n",
    "         case when date between '2020-02-01' and  '2021-04-01' then 'TRAIN'\n",
    "          when date between '2021-05-01' and '2021-05-31' then 'VALIDATE'\n",
    "         else 'TEST' end as split_col\n",
    "         from `cpg-cdp.trendspotting.futurama_weekly`\n",
    "         WHERE date between '2020-07-01' and '2021-12-31'\n",
    "         )\n",
    "         SELECT * EXCEPT (volume, score, geo_type) from raw_data\n",
    "    )\n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'bq://{combined_preds_forecast_table_name}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b85b02-06d5-453c-b401-384542d7c7e4",
   "metadata": {},
   "source": [
    "### Custom component to recast original ranking to an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb11d6a-6e20-4314-b52b-67e28b79c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def rank_str_to_int(\n",
    "  project: str,\n",
    "  dataset: str,\n",
    "  source_table: str,\n",
    "  forecast_model: Artifact,\n",
    "  override: str = 'False',\n",
    ") -> NamedTuple('Outputs', [('clean_forecast_table', str)]):\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    override = bool(override)\n",
    "    bq_client = bigquery.Client(project=project)\n",
    "    source_table_name = source_table_name.strip('bq://')\n",
    "    clean_table_name = f'{project}.{dataset}.{source_table}_fixed'\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"\n",
    "    create table `{clean_table_name}` as\n",
    "    SELECT *, cast(category_rank as int) as category_rank_int  FROM `{source_table}` \n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'{clean_table_name}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f26d0a-e93d-48c8-af3d-214ba1b0992a",
   "metadata": {},
   "source": [
    "### K-Means Clustering in BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4432e7cd-92e1-493b-b989-153202b3ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def k_means_model_bq(\n",
    "  project: str,\n",
    "  dataset: str,\n",
    "  source_table: str,\n",
    "  k_means_model_name: str,\n",
    "  n_clusters: int,\n",
    "  override: str = 'False',\n",
    ") -> NamedTuple('Outputs', [('k_means_model_name', str)]):\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    bq_client = bigquery.Client(project=project)\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"\n",
    "    CREATE OR REPLACE MODEL\n",
    "    trendspotting.{k_means_model_name} OPTIONS(model_type='kmeans',\n",
    "    kmeans_init_method = 'KMEANS++',\n",
    "    num_clusters={n_clusters}) AS (\n",
    "\n",
    "    with six_mo_val as (select *, predicted_category_rank.value as six_mo_forecast from `cpg-cdp.trendspotting.{source_table}` \n",
    "        where predicted_on_date = '2021-06-06' and date = '2021-12-26')\n",
    "    , three_mo_val as (select series_id, predicted_category_rank.value as three_mo_forecast from `cpg-cdp.trendspotting.{source_table}` \n",
    "        where predicted_on_date = '2021-06-06' and date = '2021-09-26')\n",
    "    , one_mo_val as (select series_id, predicted_category_rank.value as one_mo_forecast from `cpg-cdp.trendspotting.{source_table}` \n",
    "        where predicted_on_date = '2021-06-06' and date = '2021-07-11')\n",
    "    , actuals as (select distinct series_id, max(category_rank_int) as current_rank from `cpg-cdp.trendspotting.{source_table}` \n",
    "        where predicted_on_date = '2021-06-06' and date = '2021-06-06' group by series_id)\n",
    "    select a.* \n",
    "        except(date, predicted_on_date, predicted_category_rank, split_col,category_rank, category_rank_int, series_id), \n",
    "        b.three_mo_forecast, \n",
    "        c.one_mo_forecast, \n",
    "        d.current_rank\n",
    "    from six_mo_val a\n",
    "        inner join three_mo_val b on (a.series_id = b.series_id)  \n",
    "        inner join one_mo_val c on (a.series_id = c.series_id)\n",
    "        inner join actuals d on (a.series_id = d.series_id)\n",
    "        )\n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'{k_means_model_name}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09854d77-5c2f-4066-a3f7-ade727c3b719",
   "metadata": {},
   "source": [
    "### Predict k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "300c1930-bea4-445c-8904-e5e9e354aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==2.18.0'],\n",
    ")\n",
    "def k_means_predict_bq(\n",
    "  project: str,\n",
    "  dataset: str,\n",
    "  source_table: str,\n",
    "  k_means_model_name: str,\n",
    "  n_clusters: int,\n",
    "  override: str = 'False',\n",
    ") -> NamedTuple('Outputs', [('k_means_table_name', str)]):\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    bq_client = bigquery.Client(project=project)\n",
    "    (\n",
    "    bq_client.query(\n",
    "      f\"\"\"\n",
    "      CREATE TABLE IF NOT EXISTS {project}.trendspotting.{source_table}_n_clus{n_clusters} as (\n",
    "    ML.PREDICT( MODEL {project}.{k_means_model_name},\n",
    "    (\n",
    "\n",
    "    with six_mo_val as (select *, predicted_category_rank.value as six_mo_forecast from `cpg-cdp.trendspotting.{source_table}` \n",
    "        where predicted_on_date = '2021-06-06' and date = '2021-12-26')\n",
    "    , three_mo_val as (select series_id, predicted_category_rank.value as three_mo_forecast from `cpg-cdp.trendspotting.{source_table}` \n",
    "        where predicted_on_date = '2021-06-06' and date = '2021-09-26')\n",
    "    , one_mo_val as (select series_id, predicted_category_rank.value as one_mo_forecast from `cpg-cdp.trendspotting.{source_table}` \n",
    "        where predicted_on_date = '2021-06-06' and date = '2021-07-11')\n",
    "    , actuals as (select distinct series_id, max(category_rank_int) as current_rank from `cpg-cdp.trendspotting.{source_table}` \n",
    "        where predicted_on_date = '2021-06-06' and date = '2021-06-06' group by series_id)\n",
    "    select a.* \n",
    "        except(date, predicted_on_date, predicted_category_rank, split_col,category_rank, category_rank_int, series_id), \n",
    "        b.three_mo_forecast, \n",
    "        c.one_mo_forecast, \n",
    "        d.current_rank\n",
    "    from six_mo_val a\n",
    "        inner join three_mo_val b on (a.series_id = b.series_id)  \n",
    "        inner join one_mo_val c on (a.series_id = c.series_id)\n",
    "        inner join actuals d on (a.series_id = d.series_id)\n",
    "\n",
    "        ))\n",
    "          \"\"\"\n",
    "    )\n",
    "    .result()\n",
    "    )\n",
    "\n",
    "    return (\n",
    "    f'{k_means_table}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca3afee2-470b-445d-8360-1cbf89b3d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "VERSION = 'poc_rmsle'\n",
    "rmse_model_version = 'poc_rmsle'\n",
    "\n",
    "COLUMN_TRANSFORMATIONS = [\n",
    "  {\n",
    "    \"timestamp\": {\n",
    "      \"columnName\": \"date\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"categorical\": {\n",
    "      \"columnName\": \"geo_id\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"text\": {\n",
    "      \"columnName\": \"geo_name\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"categorical\": {\n",
    "      \"columnName\": \"category_id\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"text\": {\n",
    "      \"columnName\": \"term\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"numeric\": {\n",
    "      \"columnName\": \"category_rank\"\n",
    "    }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9cfd3a-e4b3-4de6-9486-901b6ab7583f",
   "metadata": {},
   "source": [
    "### Pipeline \n",
    "\n",
    "Uses custom components, also uses reusable vertex components for creating the training dataset and training the forecast models\n",
    "\n",
    "Notice the output for testing in BQ is set by `target_table`, assigned to `export_evaluated_data_items_bigquery_destination_uri`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61b9d896-c952-40b1-ba3b-4b14a973fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_TAG = 'trendspotting-pipeline' # <--- TODO; optionally name pipeline\n",
    "@kfp.v2.dsl.pipeline(\n",
    "  name=f'{VERSION}-{PIPELINE_TAG}'.replace('_', '-'),\n",
    "        pipeline_root=PIPELINES_FILEPATH,\n",
    "\n",
    ")\n",
    "def pipeline(\n",
    "  vertex_project: str,\n",
    "  location: str,\n",
    "  version: str,\n",
    "  data_source_dataset: str,\n",
    "  ds_display_name: str,\n",
    "  # activities_expected_historical_last_date: str,\n",
    "  context_window: int,\n",
    "  forecast_horizon: int,\n",
    "  override: str,\n",
    "  target_table: str,\n",
    "  k_means_name: str,\n",
    "  n_clusters: int,\n",
    "  budget_milli_node_hours: int = 16000,\n",
    "):\n",
    "\n",
    "    \n",
    "    create_prediction_dataset_op = create_prediction_dataset(\n",
    "        project = vertex_project,\n",
    "        dataset = 'trendspotting',\n",
    "        source_table_uri = data_source_dataset,\n",
    "        override = 'False',\n",
    "    )\n",
    "\n",
    "\n",
    "    time_series_dataset_create_op = gcc_aip.TimeSeriesDatasetCreateOp(\n",
    "        display_name=ds_display_name, \n",
    "        bq_source=create_prediction_dataset_op.outputs['training_data_table_uri'],\n",
    "        project=vertex_project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    rmse_model_op = gcc_aip_forecasting.ForecastingTrainingWithExperimentsOp(\n",
    "        display_name=f'train-{rmse_model_version}',\n",
    "        model_display_name=rmse_model_version,\n",
    "        dataset=time_series_dataset_create_op.outputs['dataset'],\n",
    "        context_window=context_window,\n",
    "        forecast_horizon=forecast_horizon,\n",
    "        budget_milli_node_hours=budget_milli_node_hours,\n",
    "        project=vertex_project,\n",
    "        location=location,\n",
    "        export_evaluated_data_items=True,\n",
    "        export_evaluated_data_items_override_destination=True,\n",
    "        target_column='category_rank',\n",
    "        time_column='date',\n",
    "        time_series_identifier_column='series_id',\n",
    "        time_series_attribute_columns=['geo_name', 'geo_id', 'category_id', 'term'],\n",
    "        unavailable_at_forecast_columns=['category_rank'],\n",
    "        available_at_forecast_columns=['date'],\n",
    "        data_granularity_unit='week',\n",
    "        data_granularity_count=1,\n",
    "        predefined_split_column_name= 'split_col', \n",
    "        optimization_objective='minimize-rmsle',\n",
    "        column_transformations=COLUMN_TRANSFORMATIONS,\n",
    "        export_evaluated_data_items_bigquery_destination_uri = target_table, # must be format:``bq://<project_id>:<dataset_id>:<table>``\n",
    "    )\n",
    "\n",
    "    clean_table_op = rank_str_to_int(\n",
    "        project = vertex_project,\n",
    "        dataset = 'trendspotting',\n",
    "        source_table = target_table,\n",
    "        forecast_model = rmse_model_op.outputs['model'],\n",
    "    )\n",
    "\n",
    "\n",
    "    k_means_train_op = k_means_model_bq(\n",
    "        project = vertex_project,\n",
    "        dataset = 'trendspotting',\n",
    "        source_table = clean_table_op.outputs['clean_forecast_table'],\n",
    "        k_means_model_name = k_means_name,\n",
    "        n_clusters = n_clusters,\n",
    "    )\n",
    "\n",
    "    k_means_predict_op = k_means_predict_bq(\n",
    "        project = vertex_project,\n",
    "        dataset = 'trendspotting',\n",
    "        source_table = clean_table_op.outputs['clean_forecast_table'],\n",
    "        k_means_model_name = k_means_train_op.outputs['k_means_model_name'],\n",
    "        n_clusters = n_clusters,\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8d9ec46-05d3-4dba-a935-c58026a5e822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='trendspotting.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f6a37-e374-4570-b462-fd9d6b93691f",
   "metadata": {},
   "source": [
    "### Set parameters for pipeline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a112290-eb83-48b6-8006-fdd244a02679",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'cpg-cdp' # <--- TODO: If not set\n",
    "LOCATION = 'us-central1' # <--- TODO: If not set\n",
    "SERVICE_ACCOUNT = 'vertex-pipelines@cpg-cdp.iam.gserviceaccount.com' , # <--- TODO: Change This if needed\n",
    "N_CLUSTERS = 20\n",
    "K_MEANS_MODEL_NAME = f\"trendspotting_{N_CLUSTERS}\"\n",
    "\n",
    "\n",
    "# BQ dataset for source data source\n",
    "DATA_SOURCE_DATASET = 'futurama_weekly'\n",
    "\n",
    "# TODO: Forecasting Configuration:\n",
    "HISTORY_WINDOW_n = 52 #  {type: 'integer'} # context_window\n",
    "FORECAST_HORIZON = 52 #  {type: 'integer'} \n",
    "BUDGET_MILLI_NODE_HOURS = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bc9f7ac-9937-4f1a-baa4-643d6e688648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b46db-4137-4ab6-8c68-b9b1d4153b55",
   "metadata": {},
   "source": [
    "### Run the pipeline\n",
    "Follow the link to see the exectution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ad4b6c-5843-4f36-ba64-3b1869c630e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/939655404703/locations/us-central1/pipelineJobs/poc-rmsle-trendspotting-pipeline-20220210221600\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/939655404703/locations/us-central1/pipelineJobs/poc-rmsle-trendspotting-pipeline-20220210221600')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/poc-rmsle-trendspotting-pipeline-20220210221600?project=939655404703\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "PIPELINE_PARAMETERS = {\n",
    "      'vertex_project': PROJECT_ID,\n",
    "      'location': LOCATION,\n",
    "      'version': VERSION,\n",
    "      'data_source_dataset': DATA_SOURCE_DATASET,\n",
    "      'context_window': HISTORY_WINDOW_n,\n",
    "      'forecast_horizon': FORECAST_HORIZON,\n",
    "      'budget_milli_node_hours': BUDGET_MILLI_NODE_HOURS,\n",
    "      'ds_display_name': '20-21-clean',\n",
    "      'k_means_name': K_MEANS_MODEL_NAME,\n",
    "      'n_clusters': N_CLUSTERS,\n",
    "      'override' : 'false',\n",
    "      'target_table' : f'{PROJECT_ID}:trendspotting.predict_c{HISTORY_WINDOW_n}_h{FORECAST_HORIZON}_rmsle'\n",
    "    }\n",
    "\n",
    "job = aiplatform.PipelineJob(display_name = 'trendspotting_test',\n",
    "                             template_path = 'trendspotting.json',\n",
    "                             pipeline_root = PIPELINES_FILEPATH,\n",
    "                             parameter_values = PIPELINE_PARAMETERS,\n",
    "                             project = PROJECT_ID,\n",
    "                             location = LOCATION)\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28adba6-e7da-48cf-b9bf-8b1082e7822b",
   "metadata": {},
   "source": [
    "### Link to downstream report\n",
    "[here](https://datastudio.google.com/c/u/0/reporting/7f55644b-679b-4123-b13d-ce6f90fbd436/page/uhSlC/edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971aaad-9cbf-4521-bf5b-3f1cd240df69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
