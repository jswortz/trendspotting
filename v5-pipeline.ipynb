{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e4af0c-18f3-43f4-b418-17b48f156ef8",
   "metadata": {},
   "source": [
    "# Trendspotting POC\n",
    "\n",
    "Goal of this notebook is to\n",
    "* Load signals data into a managed vertex dataset for time series forecasting\n",
    "* Create a forecast prediction model for each term, geo and category combination\n",
    "* Project the forecasts on a holdout set of data to assess performance and trends\n",
    "* Clean up results of test predictions\n",
    "* Cluster test predictions\n",
    "* Create dashboard for backtesting\n",
    "\n",
    "End users would take this parameterized pipeline to produce futurama backtests using clustering and forecasting\n",
    "\n",
    "[Source Control Link](https://source.cloud.google.com/cpg-cdp/trendspotting/+/master:pipeline_train.ipynb)\n",
    "\n",
    "When run - the piepline will look something like this:\n",
    "\n",
    "![pipeline example](img/pipeline_example.png)\n",
    "\n",
    "[Link to pipeline](https://pantheon.corp.google.com/vertex-ai/locations/us-central1/pipelines/runs/report-pipe-trendspotting-pipeline-20220309212043?authuser=0&project=cpg-cdp)\n",
    "## Install packages, create bucket (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d303d30-5821-4179-a13d-3c49455e72ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip3 install -U google-cloud-storage $USER_FLAG\n",
    "# ! pip3 install kfp google-cloud-pipeline-components\n",
    "# # !git clone https://github.com/kubeflow/pipelines.git\n",
    "# # !pip install pipelines/components/google-cloud/.\n",
    "# !pip install google-cloud-aiplatform\n",
    "# from google_cloud_pipeline_components.v1.bigquery import BigqueryCreateModelJobOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15945c-b978-45c4-9ecc-87e17c4097b6",
   "metadata": {},
   "source": [
    "### Import libs and types for KFP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7682f283-85c0-416b-9e24-5ae00e6b4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install protobuf==3.2.0\n",
    "# ! pip install google-cloud-pipeline-components==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b2a410-def8-43de-aa41-2ed9efe75d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from google_cloud_pipeline_components.v1.bigquery import BigqueryCreateModelJobOp\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "from google_cloud_pipeline_components.v1 import dataset as dataset_pipeline_components\n",
    "from google_cloud_pipeline_components.v1.automl import training_job as training_pipeline_components\n",
    "\n",
    "import kfp\n",
    "import kfp.dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95fbc67-a62b-42f2-a756-a6e304bf582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"cpg-cdp\"\n",
    "VERTEX_PROJECT = PROJECT_ID\n",
    "LOCATION = \"us-central1\"\n",
    "BUCKET = \"gs://trendspotting-pipeline\"\n",
    "SA = \"vertex-pipelines@cpg-cdp.iam.gserviceaccount.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084eab4d",
   "metadata": {},
   "source": [
    "One time - create the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03556060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil mb -l $LOCATION $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b675de8f-00f9-4d2f-9d5c-73e3d9e78683",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINES = {}\n",
    "\n",
    "PIPELINES_FILEPATH = BUCKET\n",
    "\n",
    "if os.path.isfile(PIPELINES_FILEPATH):\n",
    "    with open(PIPELINES_FILEPATH) as f:\n",
    "        PIPELINES = json.load(f)\n",
    "else:\n",
    "    PIPELINES = {}\n",
    "\n",
    "\n",
    "def save_pipelines():\n",
    "    with open(PIPELINES_FILEPATH, \"w\") as f:\n",
    "        json.dump(PIPELINES, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d66fd7-22b7-4682-ad27-dfdb3bc1c551",
   "metadata": {},
   "source": [
    "### Pipeline meta-paramter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a112290-eb83-48b6-8006-fdd244a02679",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = (SA,)  # <--- TODO: Change This if needed\n",
    "N_CLUSTERS = 20\n",
    "# BQ dataset for source data source\n",
    "TOP_N_RESULTS = 50\n",
    "# TODO: Forecasting Configuration:\n",
    "HISTORY_WINDOW_n = 52  #  {type: 'integer'} # context_window\n",
    "FORECAST_HORIZON = 52  #  {type: 'integer'}\n",
    "BUDGET_MILLI_NODE_HOURS = 20000\n",
    "BUDGET_MILLI_NODE_HOURS_CLUSTER = 1000\n",
    "BUDGET_HOURS_CLASSIFICATION = 1\n",
    "CATEGORY_ID = 10889\n",
    "\n",
    "SRC_TABLE_ID = \"cuisines_10889_thailand_2764\"\n",
    "# SRC_TABLE_ID = 'cuisines_10889_malaysia_2458'\n",
    "# SRC_TABLE_ID = 'skincare_10047_unitedstates_2840'\n",
    "\n",
    "SRC_TABLE = f\"{PROJECT_ID}.trends_data.{SRC_TABLE_ID}\"\n",
    "K_MEANS_MODEL_NAME = f\"cpg-cdp.trendspotting.{SRC_TABLE_ID}_trendspotting_{N_CLUSTERS}\"\n",
    "MODEL_NAME = f\"cpg-cdp.trendspotting.{SRC_TABLE_ID}_kmeans_{N_CLUSTERS}\"\n",
    "\n",
    "VERSION = \"v7_1\"\n",
    "\n",
    "TRAIN_ST = \"2021-08-29\"\n",
    "TRAIN_END = \"2022-02-13\"\n",
    "VALID_ST = \"2022-02-13\"\n",
    "VALID_END = \"2022-02-27\"\n",
    "PREDICT_ON_DT = \"2022-03-06\"\n",
    "SIX_MONTH_DT = \"2022-10-02\"\n",
    "\n",
    "categories = [\"NA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46e5f2-b27f-4286-98e2-83f11962f217",
   "metadata": {},
   "source": [
    "### Component Code is organized in the `src/components` module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9cfd3a-e4b3-4de6-9486-901b6ab7583f",
   "metadata": {},
   "source": [
    "### Pipeline \n",
    "\n",
    "Uses custom components, also uses reusable vertex components for creating the training dataset and training the forecast models\n",
    "\n",
    "Notice the output for testing in BQ is set by `target_table`, assigned to `export_evaluated_data_items_bigquery_destination_uri`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ec99f8a-ec3a-45d9-89c9-7f24e8d8f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components import components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61b9d896-c952-40b1-ba3b-4b14a973fcbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/w0cnnbpj7c38b0j1gjh338f800ttdl/T/ipykernel_45010/2648030416.py:218: DeprecationWarning: dsl.Condition is deprecated. Please use dsl.If instead.\n",
      "  with kfp.dsl.Condition(sct_exists_task.output == \"True\"):\n",
      "/var/folders/3v/w0cnnbpj7c38b0j1gjh338f800ttdl/T/ipykernel_45010/2648030416.py:327: DeprecationWarning: dsl.Condition is deprecated. Please use dsl.If instead.\n",
      "  with kfp.dsl.Condition(sct_exists_task.output == \"False\"):\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_TAG = f\"{SRC_TABLE_ID}-trendspotting-pipeline-{VERSION}\"  # <--- TODO; optionally name pipeline\n",
    "\n",
    "\n",
    "@kfp.dsl.pipeline(\n",
    "    name=f\"{PIPELINE_TAG}\".replace(\"_\", \"-\"),\n",
    "    pipeline_root=PIPELINES_FILEPATH,\n",
    ")\n",
    "def pipeline(\n",
    "    vertex_project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    ds_display_name_terms: str,\n",
    "    ds_display_name_cluster: str,\n",
    "    label_table: str,\n",
    "    scored_classification_table: str,\n",
    "    classification_train_table: str,\n",
    "    classification_model_name: str,\n",
    "    classification_model_budget: int,\n",
    "    auto_cluster_train_table: str,\n",
    "    auto_min_cluster: int,\n",
    "    auto_max_cluster: int,\n",
    "    auto_cluster_target_table: str,\n",
    "    label_list: list,\n",
    "    train_st: str,\n",
    "    train_end: str,\n",
    "    valid_st: str,\n",
    "    valid_end: str,\n",
    "    predict_on_dt: str,\n",
    "    fix_embed_target: str,\n",
    "    n_clusters: int,\n",
    "    top_n_results: int,\n",
    "    six_month_dt: str,\n",
    "    source_table: str,\n",
    "    target_term_forecast_table: str,\n",
    "    target_cluster_forecast_table: str,\n",
    "    budget_milli_node_hours: int,\n",
    "    budget_milli_node_hours_cluster: int,\n",
    "    context_window: int,\n",
    "    forecast_horizon: int,\n",
    "    top_movers_target_table: str,\n",
    "    cluster_table_agg: str,\n",
    "    cluster_table: str,\n",
    "    subcat_id: int,\n",
    "    model_name: str,\n",
    "    cluster_table_agg_basic: str,\n",
    "    target_cluster_forecast_table_basic: str,\n",
    "    target_cluster_forecast_table_basic_partitioned: str,\n",
    "    sustained_riser_table: str,\n",
    "):\n",
    "\n",
    "    embed_terms = (\n",
    "        components.create_prediction_dataset_term_level(\n",
    "            target_table=f\"{vertex_project}.trends_pipeline.{SRC_TABLE_ID}_ETL_futurama_weekly_embed_{VERSION}\",\n",
    "            source_table_uri=source_table,\n",
    "            train_st=train_st,\n",
    "            train_end=train_end,\n",
    "            valid_st=valid_st,\n",
    "            valid_end=valid_end,\n",
    "            subcat_id=subcat_id,\n",
    "        )\n",
    "        .set_display_name(\"Add embeddings and split data\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    fix_embed = (\n",
    "        components.prep_forecast_term_level(\n",
    "            source_table=embed_terms.outputs[\"training_data_table_uri\"],\n",
    "            target_table=fix_embed_target,\n",
    "        )\n",
    "        .set_display_name(\"Prep Data For Training\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    time_series_dataset_create_op = (\n",
    "        dataset_pipeline_components.TimeSeriesDatasetCreateOp(\n",
    "            display_name=ds_display_name_terms,\n",
    "            bq_source=fix_embed.outputs[\"term_train_table\"],\n",
    "            project=vertex_project,\n",
    "            location=location,\n",
    "        )\n",
    "        .set_display_name(\"Prep data for training\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    term_forecasting_op = (\n",
    "        training_pipeline_components.AutoMLForecastingTrainingJobRunOp(\n",
    "            display_name=f\"train-point-forecast-futurama\",\n",
    "            model_display_name=\"point-forecast-futurama\",\n",
    "            dataset=time_series_dataset_create_op.outputs[\"dataset\"],\n",
    "            context_window=context_window,\n",
    "            forecast_horizon=forecast_horizon,\n",
    "            budget_milli_node_hours=budget_milli_node_hours,\n",
    "            project=vertex_project,\n",
    "            location=location,\n",
    "            export_evaluated_data_items=True,\n",
    "            export_evaluated_data_items_override_destination=True,\n",
    "            target_column=\"score\",\n",
    "            time_column=\"date\",\n",
    "            time_series_identifier_column=\"series_id\",\n",
    "            time_series_attribute_columns=[\n",
    "                \"sentences\",\n",
    "                \"geo_id\",\n",
    "                \"emb1\",\n",
    "                \"emb2\",\n",
    "                \"emb3\",\n",
    "                \"emb4\",\n",
    "                \"emb5\",\n",
    "                \"emb6\",\n",
    "                \"emb7\",\n",
    "                \"emb8\",\n",
    "                \"emb9\",\n",
    "                \"emb10\",\n",
    "                \"emb11\",\n",
    "                \"emb12\",\n",
    "                \"emb13\",\n",
    "                \"emb14\",\n",
    "                \"emb15\",\n",
    "                \"emb16\",\n",
    "                \"emb17\",\n",
    "                \"emb18\",\n",
    "                \"emb19\",\n",
    "                \"emb20\",\n",
    "            ],\n",
    "            unavailable_at_forecast_columns=[\"score\"],\n",
    "            available_at_forecast_columns=[\"date\"],\n",
    "            data_granularity_unit=\"week\",\n",
    "            data_granularity_count=1,\n",
    "            predefined_split_column_name=\"split_col\",\n",
    "            optimization_objective=\"minimize-rmse\",\n",
    "            column_specs={\n",
    "                \"date\": \"timestamp\",\n",
    "                \"geo_id\": \"categorical\",\n",
    "                \"score\": \"numeric\",\n",
    "                \"sentences\": \"categorical\",\n",
    "                \"emb1\": \"numeric\",\n",
    "                \"emb2\": \"numeric\",\n",
    "                \"emb3\": \"numeric\",\n",
    "                \"emb4\": \"numeric\",\n",
    "                \"emb5\": \"numeric\",\n",
    "                \"emb6\": \"numeric\",\n",
    "                \"emb7\": \"numeric\",\n",
    "                \"emb8\": \"numeric\",\n",
    "                \"emb9\": \"numeric\",\n",
    "                \"emb10\": \"numeric\",\n",
    "                \"emb11\": \"numeric\",\n",
    "                \"emb12\": \"numeric\",\n",
    "                \"emb13\": \"numeric\",\n",
    "                \"emb14\": \"numeric\",\n",
    "                \"emb15\": \"numeric\",\n",
    "                \"emb16\": \"numeric\",\n",
    "                \"emb17\": \"numeric\",\n",
    "                \"emb18\": \"numeric\",\n",
    "                \"emb19\": \"numeric\",\n",
    "                \"emb20\": \"numeric\",\n",
    "            },\n",
    "            export_evaluated_data_items_bigquery_destination_uri=target_term_forecast_table,  # must be format:``bq://<project_id>:<dataset_id>:<table>``\n",
    "        )\n",
    "        .set_display_name(\"Forecast term-level\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    sustained_risers_data_op = (\n",
    "        components.sustained_riser_report(\n",
    "            source_table=target_term_forecast_table,\n",
    "            target_table=sustained_riser_table,\n",
    "            top_n=top_n_results,\n",
    "            predicted_on_dt=predict_on_dt,\n",
    "        )\n",
    "        .after(term_forecasting_op)\n",
    "        .set_display_name(\"Create Sustained Riser Table\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    top_movers_data_op = (\n",
    "        components.create_top_mover_table(\n",
    "            source_table=target_term_forecast_table,\n",
    "            target_table=top_movers_target_table,\n",
    "            predict_on_dt=predict_on_dt,\n",
    "            six_month_dt=six_month_dt,\n",
    "            trained_model=term_forecasting_op.outputs[\"model\"],\n",
    "            top_n_results=top_n_results,\n",
    "        )\n",
    "        .set_display_name(\"Generate the top mover table\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    top_mover_post_process = (\n",
    "        components.alter_topmover_schema(source_table=top_movers_target_table)\n",
    "        .after(top_movers_data_op)\n",
    "        .set_caching_options(True)\n",
    "        .set_display_name(\"Adding descriptions to the output table\")\n",
    "    )\n",
    "\n",
    "    # HIGH LEVEL REPORT PIPELINE STARTS HERE\n",
    "\n",
    "    #######################################\n",
    "\n",
    "    model_train_sql = components.get_model_train_sql(\n",
    "        model_name, n_clusters, source_table, train_st, subcat_id\n",
    "    )\n",
    "    # tell if the scored topic tables exist\n",
    "\n",
    "    sct_exists_task = components.if_tbl_exists(\n",
    "        table_ref=label_table, project_id=vertex_project\n",
    "    )\n",
    "    with kfp.dsl.Condition(sct_exists_task.output == \"True\"):\n",
    "        ### if labeled data exists, we will create a model and auto cluster each category\n",
    "\n",
    "        train_model_op = (\n",
    "            components.train_classification_model(\n",
    "                target_table=scored_classification_table,\n",
    "                source_table=fix_embed.outputs[\"term_train_table\"],\n",
    "                label_table=label_table,\n",
    "                train_table=classification_train_table,\n",
    "                classification_model_name=classification_model_name,\n",
    "                project_id=vertex_project,\n",
    "                classification_budget_hours=classification_model_budget,\n",
    "            )\n",
    "            .set_display_name(\"Train classification model on examples\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "        auto_cluster_op = (\n",
    "            components.auto_cluster(\n",
    "                cluster_min=auto_min_cluster,\n",
    "                cluster_max=auto_max_cluster,\n",
    "                labels=label_list,\n",
    "                cluster_train_table=auto_cluster_train_table,\n",
    "                classified_terms_table=train_model_op.output,\n",
    "                target_table=auto_cluster_target_table,\n",
    "                project_id=vertex_project,\n",
    "            )\n",
    "            .set_display_name(\"Auto cluster each category\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "        aggregate_cluster_op = (\n",
    "            components.aggregate_clusters(\n",
    "                source_table=cluster_table,\n",
    "                category_table=auto_cluster_op.output,\n",
    "                target_table=cluster_table_agg,\n",
    "                train_st=train_st,\n",
    "                train_end=train_end,\n",
    "                valid_st=valid_st,\n",
    "                valid_end=valid_end,\n",
    "                model_name=model_name,\n",
    "            )\n",
    "            .set_display_name(\"Aggregate category clusters\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "        time_series_dataset_create_op_high_level = (\n",
    "            dataset_pipeline_components.TimeSeriesDatasetCreateOp(\n",
    "                display_name=ds_display_name_cluster,\n",
    "                bq_source=aggregate_cluster_op.outputs[\"term_cluster_agg_table\"],\n",
    "                project=vertex_project,\n",
    "                location=location,\n",
    "            )\n",
    "            .set_display_name(\"Forecast term-level\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "        term_forecasting_op = (\n",
    "            training_pipeline_components.AutoMLForecastingTrainingJobRunOp(\n",
    "                display_name=f\"train-cluster-forecast-futurama\",\n",
    "                model_display_name=\"cluster-forecast-futurama\",\n",
    "                dataset=time_series_dataset_create_op_high_level.outputs[\"dataset\"],\n",
    "                context_window=context_window,\n",
    "                forecast_horizon=forecast_horizon,\n",
    "                budget_milli_node_hours=budget_milli_node_hours_cluster,\n",
    "                project=vertex_project,\n",
    "                location=location,\n",
    "                export_evaluated_data_items=True,\n",
    "                export_evaluated_data_items_override_destination=True,\n",
    "                target_column=\"score\",\n",
    "                time_column=\"date\",\n",
    "                time_series_identifier_column=\"series_id\",\n",
    "                time_series_attribute_columns=[\n",
    "                    \"topic_id\",\n",
    "                    \"category\",\n",
    "                    \"comments_embed_p1\",\n",
    "                    \"comments_embed_p2\",\n",
    "                    \"comments_embed_p3\",\n",
    "                    \"comments_embed_p4\",\n",
    "                    \"comments_embed_p5\",\n",
    "                    \"comments_embed_p6\",\n",
    "                    \"comments_embed_p7\",\n",
    "                    \"comments_embed_p8\",\n",
    "                    \"comments_embed_p9\",\n",
    "                    \"comments_embed_p10\",\n",
    "                    \"comments_embed_p11\",\n",
    "                    \"comments_embed_p12\",\n",
    "                    \"comments_embed_p13\",\n",
    "                    \"comments_embed_p14\",\n",
    "                    \"comments_embed_p15\",\n",
    "                    \"comments_embed_p16\",\n",
    "                    \"comments_embed_p17\",\n",
    "                    \"comments_embed_p18\",\n",
    "                    \"comments_embed_p19\",\n",
    "                    \"comments_embed_p20\",\n",
    "                ],\n",
    "                unavailable_at_forecast_columns=[\"score\"],\n",
    "                available_at_forecast_columns=[\"date\"],\n",
    "                data_granularity_unit=\"week\",\n",
    "                data_granularity_count=1,\n",
    "                predefined_split_column_name=\"split_col\",\n",
    "                optimization_objective=\"minimize-rmse\",\n",
    "                column_transformations=components.COLUMN_TRANSFORMS_CLUSTER,\n",
    "                export_evaluated_data_items_bigquery_destination_uri=target_cluster_forecast_table,  # must be format:``bq://<project_id>:<dataset_id>:<table>``\n",
    "            )\n",
    "            .set_display_name(\"Forecast category clusters\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "    with kfp.dsl.Condition(sct_exists_task.output == \"False\"):\n",
    "        train_k_means_op = (\n",
    "            BigqueryCreateModelJobOp(\n",
    "                project=PROJECT_ID, location=\"US\", query=model_train_sql\n",
    "            )\n",
    "            .set_display_name(\"Train k-means basic BQ Model\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "        create_cluster_terms_op = (\n",
    "            components.nlp_featurize_and_cluster(\n",
    "                source_table=source_table,\n",
    "                target_table=cluster_table,\n",
    "                train_st=train_st,\n",
    "                train_end=train_end,\n",
    "                subcat_id=subcat_id,\n",
    "                model_name=model_name,\n",
    "                n_clusters=n_clusters,\n",
    "            )\n",
    "            .after(train_k_means_op)\n",
    "            .set_display_name(\"Add NLP embeddings and cluster\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "        cluster_term_table_basic_post_processing = (\n",
    "            components.alter_basic_cluster_term_table(source_table=cluster_table)\n",
    "            .after(create_cluster_terms_op)\n",
    "            .set_display_name(\"Altering table descriptions\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "        aggregate_cluster_op = (\n",
    "            components.aggregate_clusters_basic(\n",
    "                source_table=create_cluster_terms_op.outputs[\"term_cluster_table\"],\n",
    "                target_table=cluster_table_agg_basic,\n",
    "                train_st=train_st,\n",
    "                train_end=train_end,\n",
    "                valid_st=valid_st,\n",
    "                valid_end=valid_end,\n",
    "            )\n",
    "            .set_display_name(\"Basic clustering (unsupervised)\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "        time_series_dataset_create_op_high_level = (\n",
    "            dataset_pipeline_components.TimeSeriesDatasetCreateOp(\n",
    "                display_name=ds_display_name_cluster,\n",
    "                bq_source=aggregate_cluster_op.outputs[\"term_cluster_agg_table\"],\n",
    "                project=vertex_project,\n",
    "                location=location,\n",
    "            )\n",
    "            .set_display_name(\"Aggregate basic clusters\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "        term_forecasting_op = (\n",
    "            training_pipeline_components.AutoMLForecastingTrainingJobRunOp(\n",
    "                display_name=f\"train-cluster-forecast-futurama\",\n",
    "                model_display_name=\"cluster-forecast-futurama\",\n",
    "                dataset=time_series_dataset_create_op_high_level.outputs[\"dataset\"],\n",
    "                context_window=context_window,\n",
    "                forecast_horizon=forecast_horizon,\n",
    "                budget_milli_node_hours=budget_milli_node_hours_cluster,\n",
    "                project=vertex_project,\n",
    "                location=location,\n",
    "                export_evaluated_data_items=True,\n",
    "                export_evaluated_data_items_override_destination=True,\n",
    "                target_column=\"score\",\n",
    "                time_column=\"date\",\n",
    "                time_series_identifier_column=\"topic_id\",\n",
    "                time_series_attribute_columns=[\n",
    "                    \"comments_embed_p1\",\n",
    "                    \"comments_embed_p2\",\n",
    "                    \"comments_embed_p3\",\n",
    "                    \"comments_embed_p4\",\n",
    "                    \"comments_embed_p5\",\n",
    "                    \"comments_embed_p6\",\n",
    "                    \"comments_embed_p7\",\n",
    "                    \"comments_embed_p8\",\n",
    "                    \"comments_embed_p9\",\n",
    "                    \"comments_embed_p10\",\n",
    "                    \"comments_embed_p11\",\n",
    "                    \"comments_embed_p12\",\n",
    "                    \"comments_embed_p13\",\n",
    "                    \"comments_embed_p14\",\n",
    "                    \"comments_embed_p15\",\n",
    "                    \"comments_embed_p16\",\n",
    "                    \"comments_embed_p17\",\n",
    "                    \"comments_embed_p18\",\n",
    "                    \"comments_embed_p19\",\n",
    "                    \"comments_embed_p20\",\n",
    "                ],\n",
    "                unavailable_at_forecast_columns=[\"score\"],\n",
    "                available_at_forecast_columns=[\"date\"],\n",
    "                data_granularity_unit=\"week\",\n",
    "                data_granularity_count=1,\n",
    "                predefined_split_column_name=\"split_col\",\n",
    "                optimization_objective=\"minimize-rmse\",\n",
    "                column_transformations=components.COLUMN_TRANSFORMS_CLUSTER,\n",
    "                export_evaluated_data_items_bigquery_destination_uri=target_cluster_forecast_table_basic,  # must be format:``bq://<project_id>:<dataset_id>:<table>``\\n\",\n",
    "            )\n",
    "            .set_display_name(\"Forecast basic clusters\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "        cluster_forecast_fix_table_op = (\n",
    "            components.create_partitioned_forecast_table(\n",
    "                source_table=target_cluster_forecast_table_basic,\n",
    "                target_table=target_cluster_forecast_table_basic_partitioned,\n",
    "            )\n",
    "            .after(term_forecasting_op)\n",
    "            .set_display_name(\"Creating final partitioned table\")\n",
    "            .set_caching_options(True)\n",
    "        )\n",
    "\n",
    "        cluster_forecast_table_post_process = (\n",
    "            components.alter_basic_cluster_forecast_table(\n",
    "                source_table=target_cluster_forecast_table_basic_partitioned\n",
    "            )\n",
    "            .after(cluster_forecast_fix_table_op)\n",
    "            .set_display_name(\"Adding table descriptions\")\n",
    "            .set_caching_options(True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f371ada-8738-4f68-9a84-a81aa14da8ca",
   "metadata": {},
   "source": [
    "## todo - to get explainations\n",
    "drop predictions on train , use `google_cloud_pipeline_components.aiplatform.ModelBatchPredictOp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8d9ec46-05d3-4dba-a935-c58026a5e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"trendspotting.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f6a37-e374-4570-b462-fd9d6b93691f",
   "metadata": {},
   "source": [
    "### Set parameters for pipeline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bc9f7ac-9937-4f1a-baa4-643d6e688648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m You do not appear to have access to project [cpg-cdp] or it does not exist.\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "! echo Y | gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b46db-4137-4ab6-8c68-b9b1d4153b55",
   "metadata": {},
   "source": [
    "### Run the pipeline\n",
    "Follow the link to see the exectution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87946ac5-3fde-4251-b5bd-8e26e184832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/939655404703/locations/us-central1/pipelineJobs/cuisines-10889-thailand-2764-trendspotting-pipeline-v7-1-20240221132548\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/939655404703/locations/us-central1/pipelineJobs/cuisines-10889-thailand-2764-trendspotting-pipeline-v7-1-20240221132548')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/cuisines-10889-thailand-2764-trendspotting-pipeline-v7-1-20240221132548?project=939655404703\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_PARAMETERS = {\n",
    "    \"subcat_id\": CATEGORY_ID,\n",
    "    \"vertex_project\": PROJECT_ID,\n",
    "    \"location\": LOCATION,\n",
    "    \"version\": VERSION,\n",
    "    \"label_table\": f\"{PROJECT_ID}.trends_pipeline.labels_jw_pl_{VERSION}\",\n",
    "    \"scored_classification_table\": f\"{PROJECT_ID}.trends_pipeline.{SRC_TABLE_ID}_ETL_classified_terms_bqml_aml_pl_{VERSION}\",\n",
    "    \"fix_embed_target\": f\"{PROJECT_ID}.trends_pipeline.{SRC_TABLE_ID}_ETL_futurama_weekly_embed_aml_pl_{VERSION}\",\n",
    "    \"drop_embed_target\": f\"{PROJECT_ID}.trends_pipeline.{SRC_TABLE_ID}_ETL_futurama_weekly_no_embed_aml_pl_{VERSION}\",\n",
    "    \"classification_train_table\": f\"{PROJECT_ID}.trends_pipeline.{SRC_TABLE_ID}_ETL_labeled_distinct_training_jw_pl_{VERSION}\",\n",
    "    \"classification_model_name\": f\"trends_pipeline.{SRC_TABLE_ID}_bqml_distinct_pl_{VERSION}\",\n",
    "    \"classification_model_budget\": BUDGET_HOURS_CLASSIFICATION,\n",
    "    \"auto_min_cluster\": 2,\n",
    "    \"auto_max_cluster\": 9,\n",
    "    \"auto_cluster_train_table\": f\"{PROJECT_ID}.trends_pipeline.{SRC_TABLE_ID}_cat_clus_train_{VERSION}\",\n",
    "    \"auto_cluster_target_table\": f\"{PROJECT_ID}.trends_results.{SRC_TABLE_ID}_categoryclusters_{VERSION}\",\n",
    "    \"label_list\": categories,\n",
    "    \"train_st\": TRAIN_ST,\n",
    "    \"train_end\": TRAIN_END,\n",
    "    \"valid_st\": VALID_ST,\n",
    "    \"valid_end\": VALID_END,\n",
    "    \"predict_on_dt\": PREDICT_ON_DT,\n",
    "    \"six_month_dt\": SIX_MONTH_DT,\n",
    "    \"context_window\": HISTORY_WINDOW_n,\n",
    "    \"forecast_horizon\": FORECAST_HORIZON,\n",
    "    \"budget_milli_node_hours\": BUDGET_MILLI_NODE_HOURS,\n",
    "    \"ds_display_name_terms\": f\"{SRC_TABLE_ID}-futurama-term-forecasts-{VERSION}\",\n",
    "    \"ds_display_name_cluster\": f\"{SRC_TABLE_ID}-futurama-clusters-{VERSION}\",\n",
    "    \"k_means_name\": K_MEANS_MODEL_NAME,\n",
    "    \"n_clusters\": N_CLUSTERS,\n",
    "    \"top_n_results\": TOP_N_RESULTS,\n",
    "    \"cluster_table_agg\": f\"{PROJECT_ID}.trends_pipeline.{SRC_TABLE_ID}_ETL_futurama_weekly_embed_cluster_agg_{N_CLUSTERS}_{VERSION}\",\n",
    "    \"target_cluster_forecast_table_basic\": f\"{PROJECT_ID}.trends_pipeline.{SRC_TABLE_ID}_predictions_cluster_basic_{N_CLUSTERS}_{VERSION}\",\n",
    "    \"target_cluster_forecast_table_basic_partitioned\": f\"{PROJECT_ID}.trends_results.{SRC_TABLE_ID}_predictions_cluster_basic_{N_CLUSTERS}_{VERSION}\",\n",
    "    \"cluster_table\": f\"{PROJECT_ID}.trends_results.{SRC_TABLE_ID}_categoryclusters_basic_{N_CLUSTERS}_{VERSION}\",\n",
    "    \"cluster_table_agg_basic\": f\"{PROJECT_ID}.trends_pipeline.{SRC_TABLE_ID}_ETL_futurama_weekly_embed_cluster_agg_basic_{N_CLUSTERS}_{VERSION}\",\n",
    "    \"override\": \"false\",\n",
    "    \"source_table\": SRC_TABLE,\n",
    "    \"target_term_forecast_table\": f\"{PROJECT_ID}.trends_pipeline.{SRC_TABLE_ID}_ETL_predict_{VERSION}\",\n",
    "    \"target_cluster_forecast_table\": f\"{PROJECT_ID}.trends_results.{SRC_TABLE_ID}_predictions_{VERSION}\",\n",
    "    \"top_movers_target_table\": f\"{PROJECT_ID}.trends_results.{SRC_TABLE_ID}_topmovers_{VERSION}\",\n",
    "    \"budget_milli_node_hours_cluster\": BUDGET_MILLI_NODE_HOURS_CLUSTER,\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"sustained_riser_table\": f\"{PROJECT_ID}.trends_results.{SRC_TABLE_ID}_sustained_risers_{VERSION}\",\n",
    "}\n",
    "\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=f'trendspotting_{PIPELINE_PARAMETERS[\"subcat_id\"]}_{VERSION}',\n",
    "    template_path=\"trendspotting.json\",\n",
    "    pipeline_root=PIPELINES_FILEPATH,\n",
    "    parameter_values=PIPELINE_PARAMETERS,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "job.submit()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
